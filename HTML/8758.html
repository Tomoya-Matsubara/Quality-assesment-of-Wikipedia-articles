

<p><strong>Statistical mechanics</strong> or <strong>statistical thermodynamics</strong><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> is a branch of <a href="physics" class="uri" title="wikilink">physics</a> that applies <a href="probability_theory" title="wikilink">probability theory</a>, which contains <a href="Mathematics" title="wikilink">mathematical</a> tools for dealing with large populations, to the study of the <em>thermodynamic</em> behavior of systems composed of a <em>large</em> <a href="number_of_particles" title="wikilink">number of particles</a>. Statistical mechanics provides a framework for relating the microscopic properties of individual atoms and molecules to the macroscopic bulk properties of materials that can be observed in everyday life, thereby explaining <a href="thermodynamics" class="uri" title="wikilink">thermodynamics</a> as a result of the classical and quantum-mechanical descriptions of statistics and mechanics at the microscopic level.</p>
<p>Statistical mechanics provides a molecular-level interpretation of macroscopic thermodynamic quantities such as <a href="work_(thermodynamics)" title="wikilink">work</a>, <a href="heat" class="uri" title="wikilink">heat</a>, <a href="thermodynamic_free_energy" title="wikilink">free energy</a>, and <a href="entropy" class="uri" title="wikilink">entropy</a>. It enables the thermodynamic properties of bulk materials to be related to the spectroscopic data of individual molecules. This ability to make macroscopic predictions based on microscopic properties is the main advantage of statistical mechanics over <a href="classical_thermodynamics" title="wikilink">classical thermodynamics</a>. Both theories are governed by the second law of thermodynamics through the medium of entropy. However, entropy in thermodynamics can only be known empirically, whereas in statistical mechanics, it is a function of the distribution of the system on its micro-states.</p>
<p>Statistical mechanics was initiated in 1870 with the work of Austrian physicist <a href="Ludwig_Boltzmann" title="wikilink">Ludwig Boltzmann</a>, much of which was collectively published in Boltzmann's 1896 <em>Lectures on Gas Theory</em>.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> Boltzmann's original papers on the statistical interpretation of thermodynamics, the <a href="H-theorem" class="uri" title="wikilink">H-theorem</a>, <a href="transport_theory" title="wikilink">transport theory</a>, <a href="thermal_equilibrium" title="wikilink">thermal equilibrium</a>, the <a href="equation_of_state" title="wikilink">equation of state</a> of gases, and similar subjects, occupy about 2,000 pages in the proceedings of the Vienna Academy and other societies. The term &quot;statistical thermodynamics&quot; was proposed for use by the American thermodynamicist and physical chemist <a href="Josiah_Willard_Gibbs" title="wikilink">J. Willard Gibbs</a> in 1902. According to Gibbs, the term &quot;statistical&quot;, in the context of mechanics, i.e. statistical mechanics, was first used by the Scottish physicist <a href="James_Clerk_Maxwell" title="wikilink">James Clerk Maxwell</a> in 1871. &quot;Probabilistic mechanics&quot; might today seem a more appropriate term, but &quot;statistical mechanics&quot; is firmly entrenched.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a></p>
<h2 id="overview">Overview</h2>
<p>The essential problem in statistical thermodynamics is to calculate the distribution of a given amount of energy <em>E</em> over <em>N</em> identical systems.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> The goal of statistical thermodynamics is to understand and to interpret the measurable macroscopic properties of materials in terms of the properties of their constituent particles and the interactions between them. This is done by connecting thermodynamic functions to quantum-mechanical equations. Two central quantities in statistical thermodynamics are the <a href="Boltzmann_factor" title="wikilink">Boltzmann factor</a> and the <a href="Partition_function_(statistical_mechanics)" title="wikilink">partition function</a>.</p>
<h2 id="fundamentals">Fundamentals</h2>

<p>Central topics covered in statistical thermodynamics include:</p>
<ul>
<li><a href="Microstate_(statistical_mechanics)" title="wikilink">Microstates</a> and configurations</li>
<li><a href="Boltzmann_distribution_law" title="wikilink">Maxwell&lt;U+2013&gt;Boltzmann distribution law</a></li>
<li><a href="partition_function_(statistical_mechanics)" title="wikilink">Partition function</a>, <a href="Configuration_integral" title="wikilink">Configuration integral</a> or <a href="configuration_integral" title="wikilink">configurational partition function</a></li>
<li><a href="Thermodynamic_equilibrium" title="wikilink">Thermodynamic equilibrium</a> - thermal, mechanical, and chemical.</li>
<li>Internal <a href="Degrees_of_freedom_(physics_and_chemistry)" title="wikilink">degrees of freedom</a> - rotation, vibration, electronic excitation, etc.</li>
<li><a href="Heat_capacity" title="wikilink">Heat capacity</a> &lt;U+2013&gt; Einstein solids, polyatomic gases, etc.</li>
<li><a href="Nernst_heat_theorem" title="wikilink">Nernst heat theorem</a></li>
<li><a href="Thermal_fluctuations" title="wikilink">Fluctuations</a></li>
<li><a href="Gibbs_paradox" title="wikilink">Gibbs paradox</a></li>
<li><a href="Degenerate_energy_level" title="wikilink">Degeneracy</a></li>
</ul>
<p>Lastly, and most importantly, the formal definition of entropy of a <a href="thermodynamic_system" title="wikilink">thermodynamic system</a> from a <a href="statistical" class="uri" title="wikilink">statistical</a> perspective is called <a href="statistical_entropy" title="wikilink">statistical entropy</a>, and is defined as:</p>
<p><br /><span class="math display"><em>S</em> = <em>k</em><sub><em>B</em></sub>ln <em>Ω</em>​</span><br /> where <em>k<sub>B</sub></em> is <a href="Boltzmann_constant" title="wikilink">Boltzmann's constant</a> 1.38066&lt;U+00D7&gt;10<sup>&lt;U+2212&gt;23</sup> J K<sup>&lt;U+2212&gt;1</sup> and &lt;U+03A9&gt; is the number of <a href="microstate_(statistical_mechanics)" title="wikilink">microstates</a> corresponding to the observed thermodynamic macrostate.</p>
<p>This equation is valid only if each microstate is equally accessible (each microstate has an equal probability of occurring).</p>
<h3 id="boltzmann-distribution">Boltzmann distribution</h3>
<p>If the system is large the <a href="Boltzmann_distribution" title="wikilink">Boltzmann distribution</a> could be used (the Boltzmann distribution is an approximate result)</p>
<p><br /><span class="math display">$$n_i \propto \exp\left(-\frac {U_i}{k_B T}\right), \,$$</span><br /> where <em>n<sub>i</sub></em> stands for the number of particles occupying level <em>i</em> or the number of feasible microstates corresponding to macrostate <em>i</em>; <em>U<sub>i</sub></em> stands for the energy of <em>i</em>; <em>T</em> stands for temperature; and <em>k<sub>B</sub></em> is the <a href="Boltzmann_constant" title="wikilink">Boltzmann constant</a>.</p>
<p>If <em>N</em> is the total number of particles or states, the distribution of probability densities follows:</p>
<p><br /><span class="math display">$$\rho _i \equiv \frac {n_i}{N} = \frac {\exp\left(-\frac {U_i}{k_B T}\right)} { \sum_j \exp\left(-\frac {U_j}{k_B T}\right)},$$</span><br /> where the sum in the denominator is over all levels.</p>
<h2 id="history">History</h2>
<p>In 1738, Swiss physicist and mathematician <a href="Daniel_Bernoulli" title="wikilink">Daniel Bernoulli</a> published <em>Hydrodynamica</em> which laid the basis for the <a href="kinetic_theory_of_gases" title="wikilink">kinetic theory of gases</a>. In this work, Bernoulli posited the argument, still used to this day, that gases consist of great numbers of molecules moving in all directions, that their impact on a surface causes the gas pressure that we feel, and that what we experience as <a href="heat" class="uri" title="wikilink">heat</a> is simply the kinetic energy of their motion.</p>
<p>In 1859, after reading a paper on the diffusion of molecules by <a href="Rudolf_Clausius" title="wikilink">Rudolf Clausius</a>, Scottish physicist <a href="James_Clerk_Maxwell" title="wikilink">James Clerk Maxwell</a> formulated the <a href="Maxwell_distribution" title="wikilink">Maxwell distribution</a> of molecular velocities, which gave the proportion of molecules having a certain velocity in a specific range. This was the first-ever statistical law in physics.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> Five years later, in 1864, <a href="Ludwig_Boltzmann" title="wikilink">Ludwig Boltzmann</a>, a young student in Vienna, came across Maxwell&lt;U+2019&gt;s paper and was so inspired by it that he spent much of his life developing the subject further.</p>
<p>Hence, the foundations of statistical thermodynamics were laid down in the late 1800s by those such as Maxwell, Boltzmann, <a href="Max_Planck" title="wikilink">Max Planck</a>, Clausius, and <a href="Josiah_Willard_Gibbs" title="wikilink">Josiah Willard Gibbs</a> who began to apply statistical and quantum atomic theory to ideal gas bodies. Predominantly, however, it was Maxwell and Boltzmann, working independently, who reached similar conclusions as to the statistical nature of gaseous bodies. Yet, one must consider Boltzmann to be the &quot;father&quot; of statistical thermodynamics with his 1875 derivation of the relationship between entropy <em>S</em> and multiplicity <em>&lt;U+03A9&gt;</em>, the number of microscopic arrangements (microstates) producing the same macroscopic state (macrostate) for a particular system.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a></p>
<h2 id="fundamental-postulate">Fundamental postulate</h2>

<p>The fundamental postulate in statistical mechanics (also known as the <em>equal a priori probability postulate</em>) is the following:</p>
<dl>

<dd><em>Given an isolated system in equilibrium, it is found with equal probability in each of its accessible <a href="microstate_(statistical_mechanics)" title="wikilink">microstates</a>.</em>
</dd>
</dl>
<p>This postulate is a fundamental assumption in statistical mechanics - it states that a system in equilibrium does not have any preference for any of its available microstates. Given &lt;U+03A9&gt; microstates at a particular energy, the probability of finding the system in a particular microstate is <em>p</em> = 1/&lt;U+03A9&gt;.</p>
<p>This postulate is necessary because it allows one to conclude that for a system at equilibrium, the thermodynamic state (macrostate) which could result from the largest number of microstates is also the most probable macrostate of the system.</p>
<p>The postulate is justified in part, for classical systems, by <a href="Liouville&#39;s_theorem_(Hamiltonian)" title="wikilink">Liouville's theorem (Hamiltonian)</a>, which shows that if the distribution of system points through accessible <a href="phase_space" title="wikilink">phase space</a> is uniform at some time, it remains so at later times.</p>
<p>Similar justification for a discrete system is provided by the mechanism of <a href="detailed_balance" title="wikilink">detailed balance</a>.</p>
<p>This allows for the definition of the <em>information function</em> (in the context of <a href="information_theory" title="wikilink">information theory</a>):</p>
<p><br /><span class="math display"><em>I</em> =  − ∑<sub><em>i</em></sub><em>ρ</em><sub><em>i</em></sub>ln <em>ρ</em><sub><em>i</em></sub> = ⟨ − ln <em>ρ</em>⟩.</span><br /> When all the probabilities &lt;U+03C1&gt;<sub><em>i</em></sub> (<a href="Rho_(letter)" title="wikilink">rho</a>) are equal, <em>I</em> is maximal, and we have minimal information about the system. When our information is maximal (i.e., one rho is equal to one and the rest to zero, such that we know what state the system is in), the function is minimal.</p>
<p>This information function is the same as the <em>reduced entropic function</em> in thermodynamics.</p>
<p>Mark Srednicki has argued that the fundamental postulate can be derived assuming only that Berry's conjecture (named after <a href="Michael_Berry_(physicist)" title="wikilink">Michael Berry</a>) applies to the system in question.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a><a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a> Berry's conjecture is believed to hold only for chaotic systems, and roughly says that the energy eigenstates are distributed as <a href="Normal_distribution" title="wikilink">Gaussian random variables</a>. Since all realistic systems with more than a handful of degrees of freedom are expected to be chaotic, this puts the fundamental postulate on firm footing. Berry's conjecture has also been shown to be equivalent to an <a href="information_theory" title="wikilink">information theoretic</a> <em>principle of least bias</em>.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a></p>
<h2 id="statistical-ensembles">Statistical ensembles</h2>

<p>The modern formulation of statistical mechanics is based on the description of the physical system by an <a href="Statistical_ensemble_(mathematical_physics)" title="wikilink">ensemble</a> that represents all possible configurations of the system and the probability of realizing each configuration.</p>
<p>Each ensemble is associated with a <a href="partition_function_(statistical_mechanics)" title="wikilink">partition function</a> that, with mathematical manipulation, can be used to extract values of thermodynamic properties of the system. According to the relationship of the system to the rest of the universe, one of three general types of ensembles may apply, in order of increasing complexity:</p>
<ul>
<li>Microcanonical ensemble: describes a completely <a href="isolated_system" title="wikilink">isolated system</a>, having constant energy, as it does not exchange energy or mass with the rest of the universe.</li>
<li>Canonical ensemble: describes a system in <a href="thermal_equilibrium" title="wikilink">thermal equilibrium</a> with its environment. It may only exchange energy in the form of heat with the outside.</li>
<li>Grand-canonical ensemble: used in open systems which exchange energy and mass with the outside.</li>
</ul>
<dl>

<dd>{| class=&quot;wikitable&quot;
</dd>
</dl>
<p>|- ! rowspan=&quot;2&quot;| Summary of ensembles ! colspan=&quot;3&quot;| Ensembles |- ! <a href="Microcanonical_ensemble" title="wikilink">Microcanonical</a> ! <a href="Canonical_ensemble" title="wikilink">Canonical</a> ! <a href="Grand_canonical_ensemble" title="wikilink">Grand canonical</a> |- ! Variables (suppressed<br />
constant for ensemble) | <em>E, N, V</em> | <em>T, N, V</em> | <em>T, &lt;U+03BC&gt;, V</em> |- ! Microscopic features |</p>
<div class="plainlist">
<ul>
<li>Number of <a href="Microstate_(statistical_mechanics)" title="wikilink">microstates</a> </small></li>
<li><center>
<p><span class="math inline"><em>Ω</em></span></p>
</center></li>
</ul>
</div>
<p>|</p>
<div class="plainlist">
<ul>
<li>Canonical partition function</li>
<li><center>
<p><span class="math inline"><em>Z</em> = ∑<sub><em>k</em></sub><em>e</em><sup> − <em>β</em><em>E</em><sub><em>k</em></sub></sup></span></p>
</center></li>
</ul>
</div>
<p>|</p>
<div class="plainlist">
<ul>
<li>Grand canonical partition function</li>
<li><center>
<p><span class="math inline"><em>Ξ</em> = ∑<sub><em>k</em></sub><em>e</em><sup> − <em>β</em>(<em>E</em><sub><em>k</em></sub> − <em>μ</em><em>N</em><sub><em>k</em></sub>)</sup></span></p>
</center></li>
</ul>
</div>
<p>|- ! Macroscopic function | <span class="math inline"><em>S</em> = <em>k</em><sub><em>B</em></sub>ln <em>Ω</em></span> | <span class="math inline"><em>F</em> =  − <em>k</em><sub><em>B</em></sub><em>T</em>ln <em>Z</em></span> | <span class="math inline"><em>F</em> − <em>μ</em><em>N</em> =  − <em>k</em><sub><em>B</em></sub><em>T</em>ln <em>Ξ</em></span> |- |}</p>
<h3 id="microcanonical-ensemble">Microcanonical ensemble</h3>

<p>In microcanonical ensemble <em>N</em>, <em>V</em> and <em>E</em> are fixed. Since the <a href="second_law_of_thermodynamics" title="wikilink">second law of thermodynamics</a> applies to isolated systems, the first case investigated will correspond to this case. The <em>Microcanonical ensemble</em> describes an isolated system.</p>
<p>The <a href="entropy" class="uri" title="wikilink">entropy</a> of such a system can only increase, so that the maximum of its entropy corresponds to an <a href="thermodynamic_equilibrium" title="wikilink">equilibrium</a> state for the system.</p>
<p>Because an <a href="isolated_system" title="wikilink">isolated system</a> keeps a constant energy, the total <a href="energy" class="uri" title="wikilink">energy</a> of the system does not fluctuate. Thus, the system can access only those of its micro-states that correspond to a given value <em>E</em> of the energy. The <a href="internal_energy" title="wikilink">internal energy</a> of the system is then strictly equal to its energy.</p>
<p>Let &lt;U+03A9&gt;(<em>E</em>) be the number of micro-states corresponding to this value of the system's energy. The macroscopic state of maximal entropy for the system is the one in which all micro-states are equally likely to occur, with probability 1/&lt;U+03A9&gt;(<em>E</em>), during the system's fluctuations, and we have for the system's <a href="entropy" class="uri" title="wikilink">entropy</a>:</p>
<p><br /><span class="math display">$$S=-k_B\sum_{i=1}^{\Omega (E)} \left[ {1\over{\Omega (E)}} \ln{1\over{\Omega (E)}}  \right ] =k_B\ln \left(\Omega (E) \right)$$</span><br /></p>
<h3 id="canonical-ensemble">Canonical ensemble</h3>

<p>In canonical ensemble <em>N</em>, <em>V</em> and <em>T</em> are fixed. Invoking the concept of the canonical ensemble, it is possible to derive the probability <em>P<sub>i</sub></em> that a macroscopic system in <a href="thermal_equilibrium" title="wikilink">thermal equilibrium</a> with its environment, will be in a given microstate with energy <em>E<sub>i</sub></em> according to the <a href="Boltzmann_distribution" title="wikilink">Boltzmann distribution</a>:</p>
<p><br /><span class="math display">$$P_i = {e^{-\beta E_i}\over{\sum_{j=1}^{j_{\rm max}}e^{-\beta E_j}}}$$</span><br /></p>
<p>using the useful definition <span class="math inline">$\beta={1\over{k_B T}}$</span>, known as the <strong><a href="Thermodynamic_beta" title="wikilink">Thermodynamic beta</a></strong> or <strong>inverse temperature</strong>.</p>
<p>The temperature <em>T</em> arises from the fact that the system is in thermal equilibrium with its environment. The probabilities of the various microstates must add to one, and the <a href="Normalizing_constant" title="wikilink">normalization factor</a> in the denominator is the canonical <a href="Partition_function_(statistical_mechanics)" title="wikilink">partition function</a>:</p>
<dl>

<dd><span class="math inline">$Z = \sum_{i=1}^{i_{\rm max}} e^{-\beta E_i}$</span>
</dd>
</dl>
<p>where <em>E<sub>i</sub></em> is the energy of the <em>i</em><sup>th</sup> microstate of the system. The partition function is a measure of the number of states accessible to the system at a given temperature. The article <a href="canonical_ensemble" title="wikilink">canonical ensemble</a> contains a derivation of Boltzmann's factor and the form of the partition function from first principles.</p>
<p>To sum up, the probability of finding a system at temperature <em>T</em> in a particular state with energy <em>E<sub>i</sub></em> is</p>
<dl>

<dd><span class="math inline">$P_i = \frac{e^{-\beta E_i}}{Z}.$</span>
</dd>
</dl>
<p>Thus the partition function looks like the weight factor for the ensemble.</p>
<h4 id="thermodynamic-connection">Thermodynamic connection</h4>
<p>The partition function can be used to find the expected (average) value of any microscopic property of the system, which can then be related to macroscopic variables. For instance, the expected value of the microscopic energy <em>E</em> is <em>interpreted</em> as the microscopic definition of the thermodynamic variable internal energy <em>U</em>, and can be obtained by taking the derivative of the partition function with respect to the temperature. Indeed,</p>
<dl>

<dd><span class="math inline">$\langle E\rangle={\sum_i E_i e^{-\beta E_i}\over Z}=-{1 \over Z} {dZ \over d\beta}$</span>
</dd>
</dl>
<p>implies, together with the interpretation of <span class="math inline">⟨<em>E</em>⟩</span> as <em>U</em>, the following microscopic definition of internal energy:</p>
<dl>

<dd><span class="math inline">$U\colon = -{d\ln Z\over d \beta}.$</span>
</dd>
</dl>
<p>The entropy can be calculated by (see <a href="Shannon_entropy" title="wikilink">Shannon entropy</a>)</p>
<dl>

<dd><span class="math inline">${S\over k} = - \sum_i p_i \ln p_i = \sum_i {e^{-\beta E_i}\over Z}(\beta E_i+\ln Z) = \ln Z + \beta U$</span>
</dd>
</dl>
<p>which implies that</p>
<dl>

<dd><span class="math inline">$-\frac{\ln(Z)}{\beta} = U - TS = F$</span>
</dd>
</dl>
<p>is the Helmholtz <a href="Thermodynamic_free_energy" title="wikilink">free energy</a> of the system or in other words,</p>
<p><br /><span class="math display"><em>Z</em> = <em>e</em><sup> − <em>β</em><em>F</em></sup>. </span><br /></p>
<p>Having microscopic expressions for the basic thermodynamic potentials <em>U</em> (internal energy), <em>S</em> (entropy) and <em>F</em> (free energy) is sufficient to derive expressions for other thermodynamic quantities. The basic strategy is as follows. There may be an intensive or extensive quantity that enters explicitly in the expression for the microscopic energy <em>E<sub>i</sub></em>, for instance magnetic field (intensive) or volume (extensive). Then, the conjugate thermodynamic variables are derivatives of the internal energy. The macroscopic magnetization (extensive) is the derivative of <em>U</em> with respect to the (intensive) magnetic field, and the pressure (intensive) is the derivative of <em>U</em> with respect to volume (extensive).</p>
<p>The treatment in this section assumes no exchange of matter (i.e. fixed mass and fixed particle numbers). However, the volume of the system is variable which means the density is also variable.</p>
<p>This probability can be used to find the average value, which corresponds to the macroscopic value, of any property, <em>J</em>, that depends on the energetic state of the system by using the formula:</p>
<dl>

<dd><span class="math inline">$\langle J \rangle  = \sum_i p_i J_i = \sum_i J_i \frac{e^{-\beta E_i}}{Z}$</span>
</dd>
</dl>
<p>where <span class="math inline">⟨<em>J</em>⟩</span> is the average value of property <em>J</em>. This equation can be applied to the internal energy, <em>U</em>:</p>
<dl>

<dd><span class="math inline">$U = \sum_i E_i \frac{e^{-\beta E_i}}{Z}.$</span>
</dd>
</dl>
<p>Subsequently, these equations can be combined with known thermodynamic relationships between <em>U</em> and <em>V</em> to arrive at an expression for pressure in terms of only temperature, volume and the partition function. Similar relationships in terms of the partition function can be derived for other thermodynamic properties as shown in the following table; <a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a></p>
<dl>

<dd>{| class=&quot;wikitable&quot;
</dd>
</dl>
<p>|- ! style=&quot;text-align: left&quot; | <a href="Hermann_Helmholtz" title="wikilink">Helmholtz</a> <a href="Helmholtz_free_energy" title="wikilink">free energy</a>: | <span class="math inline">$F = - {\ln Z\over \beta}$</span> |- ! style=&quot;text-align: left&quot; | <a href="Internal_energy" title="wikilink">Internal energy</a>: | <span class="math inline">$U = -\left( \frac{\partial\ln Z}{\partial\beta} \right)_{N,V}$</span> |- ! style=&quot;text-align: left&quot; | <a href="Pressure" class="uri" title="wikilink">Pressure</a>: | <span class="math inline">$P = -\left({\partial F\over \partial V}\right)_{N,T}= {1\over \beta} \left( \frac{\partial \ln Z}{\partial V} \right)_{N,T}$</span> |- ! style=&quot;text-align: left&quot; | <a href="Entropy" class="uri" title="wikilink">Entropy</a>: | <span class="math inline"><em>S</em> = <em>k</em>(ln <em>Z</em> + <em>β</em><em>U</em>) </span> |- ! style=&quot;text-align: left&quot; | <a href="Willard_Gibbs" title="wikilink">Gibbs</a> <a href="Gibbs_free_energy" title="wikilink">free energy</a>: | <span class="math inline">$G = F+PV=-{\ln Z\over \beta} + {V\over \beta} \left( \frac{\partial \ln Z}{\partial V}\right)_{N,T}$</span> |- ! style=&quot;text-align: left&quot; | <a href="Enthalpy" class="uri" title="wikilink">Enthalpy</a>: | <span class="math inline"><em>H</em> = <em>U</em> + <em>P</em><em>V</em> </span> |- ! style=&quot;text-align: left&quot; | Constant volume <a href="Specific_heat_capacity" title="wikilink">heat capacity</a>: | <span class="math inline">$C_V = \left( \frac{\partial U}{\partial T} \right)_{N,V}$</span> |- ! style=&quot;text-align: left&quot; | Constant pressure heat capacity: | <span class="math inline">$C_P = \left( \frac{\partial H}{\partial T} \right)_{N,P}$</span> |- ! style=&quot;text-align: left&quot; | <a href="Chemical_potential" title="wikilink">Chemical potential</a>: | <span class="math inline">$\mu_i = -{1\over \beta} \left( \frac{\partial \ln Z}{\partial N_i} \right)_{T,V,N}$</span> |- |}</p>
<p>To clarify, this is not a <a href="grand_canonical_ensemble" title="wikilink">grand canonical ensemble</a>.</p>
<p>It is often useful to consider the energy of a given molecule to be distributed among a number of modes. For example, translational energy refers to that portion of energy associated with the motion of the center of mass of the molecule. Configurational energy refers to that portion of energy associated with the various attractive and repulsive forces between molecules in a system. The other modes are all considered to be internal to each molecule. They include rotational, vibrational, electronic and nuclear modes. If we assume that each mode is independent (a questionable assumption) the total energy can be expressed as the sum of each of the components:</p>
<dl>

<dd><span class="math inline"><em>E</em> = <em>E</em><sub><em>t</em></sub> + <em>E</em><sub><em>c</em></sub> + <em>E</em><sub><em>n</em></sub> + <em>E</em><sub><em>e</em></sub> + <em>E</em><sub><em>r</em></sub> + <em>E</em><sub><em>v</em></sub>, </span>
</dd>
</dl>
<p>where the subscripts <em>t</em>, <em>c</em>, <em>n</em>, <em>e</em>, <em>r</em>, and <em>v</em> correspond to translational, configurational, nuclear, electronic, rotational and vibrational modes, respectively. The relationship in this equation can be substituted into the very first equation to give:</p>
<dl>

<dd><span class="math inline"><em>Z</em> = ∑<sub><em>i</em></sub><em>e</em><sup> − <em>β</em>(<em>E</em><sub><em>t</em><em>i</em></sub> + <em>E</em><sub><em>c</em><em>i</em></sub> + <em>E</em><sub><em>n</em><em>i</em></sub> + <em>E</em><sub><em>e</em><em>i</em></sub> + <em>E</em><sub><em>r</em><em>i</em></sub> + <em>E</em><sub><em>v</em><em>i</em></sub>)</sup></span>
</dd>
<dd><math>= \sum_i
</dd>
</dl>
<p>e^{-\beta E_{ti}} e^{-\beta E_{ci}} e^{-\beta E_{ni}} e^{-\beta E_{ei}} e^{-\beta E_{ri}} e^{-\beta E_{vi}}.</math></p>
<p><em>If</em> we can assume all these modes are completely uncoupled and uncorrelated, so all these factors are in a probability sense completely independent, then</p>
<dl>

<dd><span class="math inline"><em>Z</em> = <em>Z</em><sub><em>t</em></sub><em>Z</em><sub><em>c</em></sub><em>Z</em><sub><em>n</em></sub><em>Z</em><sub><em>e</em></sub><em>Z</em><sub><em>r</em></sub><em>Z</em><sub><em>v</em></sub>. </span>
</dd>
</dl>
<p>Thus a partition function can be defined for each mode. Simple expressions have been derived relating each of the various modes to various measurable molecular properties, such as the characteristic rotational or vibrational frequencies.</p>
<p>Expressions for the various molecular partition functions are shown in the following table.</p>
<dl>

<dd>{| class=&quot;wikitable&quot;
</dd>
</dl>
<p>|- ! style=&quot;text-align: left&quot; | Nuclear | <span class="math inline"><em>Z</em><sub><em>n</em></sub> = 1  (<em>T</em> &lt; 10<sup>8</sup><em>K</em>)</span> |- ! style=&quot;text-align: left&quot; | Electronic | <span class="math inline"><em>Z</em><sub><em>e</em></sub> = <em>W</em><sub>0</sub><em>e</em><sup><em>k</em><em>T</em><em>D</em><sub><em>e</em></sub></sup> + <em>W</em><sub>1</sub><em>e</em><sup> − <em>θ</em><sub><em>e</em>1</sub>/<em>T</em></sup> + ⋯</span> |- ! style=&quot;text-align: left&quot; | Vibrational | <span class="math inline">$Z_v = \prod_j \frac{e^{-\theta_{vj} / 2T}}{1-e^{-\theta_{vj} / T}}$</span> |- ! style=&quot;text-align: left&quot; | Rotational (linear) | <span class="math inline">$Z_r = \frac{T}{\sigma\theta_r}$</span> |- ! style=&quot;text-align: left&quot; | Rotational (non-linear) | <span class="math inline">$Z_r = \frac{1}{\sigma}\sqrt{\frac{{\pi}T^3}{\theta_A \theta_B \theta_C}}$</span> |- ! style=&quot;text-align: left&quot; | Translational | <span class="math inline">$Z_t = \frac{(2 \pi mkT)^{3/2}}{h^3}$</span> |- ! style=&quot;text-align: left&quot; | Configurational (ideal gas) | <span class="math inline"><em>Z</em><sub><em>c</em></sub> = <em>V</em> </span> |- |}</p>
<p>These equations can be combined with those in the first table to determine the contribution of a particular energy mode to a thermodynamic property. For example the &quot;rotational pressure&quot; could be determined in this manner. The total pressure could be found by summing the pressure contributions from all of the individual modes, i.e.:</p>
<dl>

<dd><span class="math inline"><em>P</em> = <em>P</em><sub><em>t</em></sub> + <em>P</em><sub><em>c</em></sub> + <em>P</em><sub><em>n</em></sub> + <em>P</em><sub><em>e</em></sub> + <em>P</em><sub><em>r</em></sub> + <em>P</em><sub><em>v</em></sub>. </span>
</dd>
</dl>
<h3 id="grand-canonical-ensemble">Grand canonical ensemble</h3>
<p>In <a href="grand_canonical_ensemble" title="wikilink">grand canonical ensemble</a> <em>V</em>, <em>T</em> and chemical potential are fixed. If the system under study is an open system (in which matter can be exchanged), <em>but</em> particle number is not conserved, we would have to introduce <a href="chemical_potential" title="wikilink">chemical potentials</a>, &lt;U+03BC&gt;<sub>j</sub>, <em>j</em> = 1,...,n and replace the canonical <a href="Partition_function_(statistical_mechanics)" title="wikilink">partition function</a> with the <a href="grand_canonical_ensemble" title="wikilink">grand canonical partition function</a>:</p>
<dl>

<dd><span class="math inline">$\Xi(V,T,\mu) = \sum_i \exp\left[\beta \left(\sum_{j=1}^n \mu_j N_{ij}-E_i\right )\right]$</span>
</dd>
</dl>
<p>where <em>N<sub>ij</sub></em> is the number of <em>j</em><sup>th</sup> species particles in the <em>i</em><sup>th</sup> configuration. Sometimes, we also have other variables to add to the <a href="Partition_function_(statistical_mechanics)" title="wikilink">partition function</a>, one corresponding to each <a href="Conservation_law" title="wikilink">conserved</a> quantity. Most of them, however, can be safely interpreted as chemical potentials. In most <a href="condensed_matter" title="wikilink">condensed matter</a> systems, things are nonrelativistic and mass is conserved. However, most condensed matter systems of interest also conserve particle number approximately (metastably) and the mass (nonrelativistically) is none other than the sum of the number of each type of particle times its mass. Mass is inversely related to density, which is the conjugate variable to pressure. For the rest of this article, we will ignore this complication and pretend chemical potentials don't matter.</p>
<p>Let's rework everything using a grand canonical ensemble this time. The volume is left fixed and does not figure in at all in this treatment. As before, <em>j</em> is the index for those particles of species <em>j</em> and <em>i</em> is the index for microstate <em>i</em>:</p>
<dl>

<dd><span class="math inline">$U = \sum_i E_i \frac{\exp(-\beta (E_i-\sum_j \mu_j N_{ij}))}{\Xi}$</span>
</dd>
<dd><span class="math inline">$N_j = \sum_i N_{ij} \frac{\exp(-\beta (E_i-\sum_j \mu_j N_{ij}))}{\Xi}.$</span>
</dd>
</dl>
<dl>

<dd>{| class=&quot;wikitable&quot;
</dd>
</dl>
<p>|- ! style=&quot;text-align: left&quot; | <a href="Grand_potential" title="wikilink">Grand potential</a>: | <span class="math inline">$\Phi_{G}  = - {\ln \Xi\over \beta}$</span> |- ! style=&quot;text-align: left&quot; | <a href="Internal_energy" title="wikilink">Internal energy</a>: | <span class="math inline">$U = -\left( \frac{\partial\ln \Xi}{\partial\beta} \right)_{\mu}+\sum_i{\mu_i\over\beta}\left({\partial \ln \Xi\over \partial \mu_i}\right )_{\beta}$</span> |- ! style=&quot;text-align: left&quot; | Particle number: | <span class="math inline">$N_i={1\over\beta}\left({\partial \ln \Xi\over \partial \mu_i}\right)_\beta$</span> |- ! style=&quot;text-align: left&quot; | <a href="Entropy" class="uri" title="wikilink">Entropy</a>: | <span class="math inline"><em>S</em> = <em>k</em>(ln <em>Ξ</em> + <em>β</em><em>U</em> − <em>β</em>∑<sub><em>i</em></sub><em>μ</em><sub><em>i</em></sub><em>N</em><sub><em>i</em></sub>) </span> |- ! style=&quot;text-align: left&quot; | <a href="Helmholtz_free_energy" title="wikilink">Helmholtz free energy</a>: | <span class="math inline">$F = \Phi_{G}+\sum_i \mu_i N_i=-{\ln \Xi\over \beta} +\sum_i{\mu_i\over \beta} \left( \frac{\partial \ln \Xi}{\partial \mu_i}\right)_{\beta}$</span> |- |}</p>
<h3 id="equivalence-between-descriptions-at-the-thermodynamic-limit">Equivalence between descriptions at the thermodynamic limit</h3>
<p>All of the above descriptions differ in the way they allow the given system to fluctuate between its configurations.</p>
<p>In the micro-canonical ensemble, the system exchanges no energy with the outside world, and is therefore not subject to energy fluctuations; in the canonical ensemble, the system is free to exchange energy with the outside in the form of <a href="heat" class="uri" title="wikilink">heat</a>.</p>
<p>In the <a href="thermodynamic_limit" title="wikilink">thermodynamic limit</a>, which is the limit of large systems, fluctuations become negligible, so that all these descriptions converge to the same description. In other words, the macroscopic behavior of a system does not depend on the particular ensemble used for its description.</p>
<p>Given these considerations, the best ensemble to choose for the calculation of the properties of a macroscopic system is that ensemble which allows the result to be derived most easily.</p>
<h2 id="random-walks">Random walks</h2>
<p>The study of long chain <a href="polymers" class="uri" title="wikilink">polymers</a> has been a source of problems within the realms of statistical mechanics since about the 1950s. One of the reasons however that scientists were interested in their study is that the equations governing the behavior of a polymer chain were independent of the chain chemistry. What is more, the governing equation turns out to be a <a href="random_walk" title="wikilink">random walk</a>, or diffusive walk, in space. Indeed, the <a href="Schr&lt;U+00F6&gt;dinger_equation" title="wikilink">Schr&lt;U+00F6&gt;dinger equation</a> is itself a <a href="diffusion_equation" title="wikilink">diffusion equation</a> in imaginary time, <em>t' = it</em>.</p>
<h3 id="random-walks-in-time">Random walks in time</h3>
<p>The first example of a random walk is one in space, whereby a particle undergoes a random motion due to external forces in its surrounding medium. A typical example would be a pollen grain in a beaker of water. If one could somehow &quot;dye&quot; the path the pollen grain has taken, the path observed is defined as a random walk.</p>
<p>Consider a toy problem, of a train moving along a 1D track in the x-direction. Suppose that the train moves either a distance of +<em>b</em> or &lt;U+2212&gt;<em>b</em> (<em>b</em> is the same for each step), depending on whether a coin lands heads or tails when flipped. Lets start by considering the statistics of the steps the toy train takes (where <em>S<sub>i</sub></em> is the ith step taken):</p>
<p><br /><span class="math display">⟨<em>S</em><sub><em>i</em></sub>⟩ = 0</span><br /> ; due to <em>a priori</em> equal probabilities</p>
<p><br /><span class="math display">⟨<em>S</em><sub><em>i</em></sub><em>S</em><sub><em>j</em></sub>⟩ = <em>b</em><sup>2</sup><em>δ</em><sub><em>i</em><em>j</em></sub>.</span><br /></p>
<p>The second quantity is known as the <a href="correlation_function" title="wikilink">correlation function</a>. The delta is the <a href="kronecker_delta" title="wikilink">kronecker delta</a> which tells us that if the indices <em>i</em> and <em>j</em> are different, then the result is 0, but if <em>i</em> = <em>j</em> then the kronecker delta is 1, so the correlation function returns a value of <em>b</em><sup>2</sup>. This makes sense, because if <em>i</em> = <em>j</em> then we are considering the same step. Rather trivially then it can be shown that the average displacement of the train on the x-axis is 0;</p>
<p><br /><span class="math display">$$x = \sum_{i=1}^{N} S_i$$</span><br /></p>
<p><br /><span class="math display">$$\langle x \rangle = \left\langle \sum_{i=1}^N S_i \right\rangle$$</span><br /></p>
<p><br /><span class="math display">$$\langle x \rangle = \sum_{i=1}^N \langle S_i \rangle.$$</span><br /></p>
<p>As stated <span class="math inline">⟨<em>S</em><sub><em>i</em></sub>⟩ = 0</span>, so the sum is still 0. It can also be shown, using the same method demonstrated above, to calculate the root mean square value of problem. The result of this calculation is given below</p>
<p><br /><span class="math display">$$x_\mathrm{rms} = \sqrt {\langle x^2 \rangle} = b \sqrt N.$$</span><br /></p>
<p>From the <a href="diffusion_equation" title="wikilink">diffusion equation</a> it can be shown that the distance a diffusing particle moves in a medium is proportional to the root of the time the system has been diffusing for, where the proportionality constant is the root of the diffusion constant. The above relation, although cosmetically different reveals similar physics, where <em>N</em> is simply the number of steps moved (is loosely connected with time) and <em>b</em> is the characteristic step length. As a consequence we can consider diffusion as a random walk process.</p>
<h3 id="random-walks-in-space">Random walks in space</h3>
<p>Random walks in space can be thought of as snapshots of the path taken by a random walker in time. One such example is the spatial configuration of long chain polymers.</p>
<p>There are two types of random walk in space: <em><a href="self-avoiding_random_walk" title="wikilink">self-avoiding random walks</a></em>, where the links of the polymer chain interact and do not overlap in space, and <em>pure random</em> walks, where the links of the polymer chain are non-interacting and links are free to lie on top of one another. The former type is most applicable to physical systems, but their solutions are harder to get at from first principles.</p>
<p>By considering a freely jointed, non-interacting polymer chain, the end-to-end vector is</p>
<p><br /><span class="math display">$$\mathbf{R} = \sum_{i=1}^{N} \mathbf r_i$$</span><br /> where <strong>r</strong><sub><em>i</em></sub> is the vector position of the <em>i</em>-th link in the chain. As a result of the <a href="central_limit_theorem" title="wikilink">central limit theorem</a>, if <em>N</em> &lt;U+226B&gt; 1 then we expect a <a href="Gaussian_distribution" title="wikilink">Gaussian distribution</a> for the end-to-end vector. We can also make statements of the statistics of the links themselves;</p>
<ul>
<li><span class="math inline">⟨<strong>r</strong><sub><em>i</em></sub>⟩ = 0</span> ; by the isotropy of space</li>
<li><span class="math inline">⟨<strong>r</strong><sub><em>i</em></sub> ⋅ <strong>r</strong><sub><em>j</em></sub>⟩ = 3<em>b</em><sup>2</sup><em>δ</em><sub><em>i</em><em>j</em></sub></span> ; all the links in the chain are uncorrelated with one another</li>
</ul>
<p>Using the statistics of the individual links, it is easily shown that</p>
<p><br /><span class="math display">⟨<strong>R</strong>⟩ = 0</span><br /></p>
<p><br /><span class="math display">⟨<strong>R</strong> ⋅ <strong>R</strong>⟩ = 3<em>N</em><em>b</em><sup>2</sup></span><br />. Notice this last result is the same as that found for random walks in time.</p>
<p>Assuming, as stated, that that distribution of end-to-end vectors for a very large number of identical polymer chains is gaussian, the probability distribution has the following form</p>
<p><br /><span class="math display">$$P = \frac{1}{\left (\frac{2 \pi N b^2}{3} \right )^{3/2}} \exp \left(\frac {- 3\mathbf R \cdot \mathbf R}{2Nb^2}\right).$$</span><br /></p>
<p>What use is this to us? Recall that according to the principle of equally likely <em>a priori</em> probabilities, the number of microstates, &lt;U+03A9&gt;, at some physical value is directly proportional to the probability distribution at that physical value, <em>viz</em>;</p>
<p><br /><span class="math display"><em>Ω</em>(<strong>R</strong>) = <em>c</em><em>P</em>(<strong>R</strong>)</span><br /></p>
<p>where <em>c</em> is an arbitrary proportionality constant. Given our distribution function, there is a maxima corresponding to <strong>R</strong> = <strong>0</strong>. Physically this amounts to there being more microstates which have an end-to-end vector of 0 than any other microstate. Now by considering</p>
<p><br /><span class="math display"><em>S</em>(<strong>R</strong>) = <em>k</em><sub><em>B</em></sub>ln <em>Ω</em>(<strong>R</strong>)</span><br /></p>
<p><br /><span class="math display"><em>Δ</em><em>S</em>(<strong>R</strong>) = <em>S</em>(<strong>R</strong>) − <em>S</em>(0)</span><br /></p>
<p><br /><span class="math display"><em>Δ</em><em>F</em> =  − <em>T</em><em>Δ</em><em>S</em>(<strong>R</strong>)</span><br /></p>
<p>where <em>F</em> is the <a href="Helmholtz_free_energy" title="wikilink">Helmholtz free energy</a>, and it can be shown that</p>
<p><br /><span class="math display">$$\Delta F = k_B T \frac {3R^2}{2Nb^2} = \frac {1}{2} K R^2 \quad ; K = \frac {3 k_B T}{Nb^2}.$$</span><br /></p>
<p>which has the same form as the <a href="potential_energy" title="wikilink">potential energy</a> of a spring, obeying <a href="Hooke&#39;s_law" title="wikilink">Hooke's law</a>.</p>
<p>This result is known as the <em>entropic spring result</em> and amounts to saying that upon stretching a polymer chain you are doing work on the system to drag it away from its (preferred) equilibrium state. An example of this is a common elastic band, composed of long chain (rubber) polymers. By stretching the elastic band you are doing work on the system and the band behaves like a conventional spring, except that unlike the case with a metal spring, all of the work done appears immediately as thermal energy, much as in the thermodynamically similar case of compressing an ideal gas in a piston.</p>
<p>It might at first be astonishing that the work done in stretching the polymer chain can be related entirely to the change in entropy of the system as a result of the stretching. However, this is typical of systems that do not store any energy as potential energy, such as ideal gases. That such systems are entirely driven by entropy changes at a given temperature, can be seen whenever it is the case that are allowed to do work on the surroundings (such as when an elastic band does work on the environment by contracting, or an ideal gas does work on the environment by expanding). Because the free energy change in such cases derives entirely from entropy change rather than internal (potential) energy conversion, in both cases the work done can be drawn entirely from thermal energy in the polymer, with 100% efficiency of conversion of thermal energy to work. In both the ideal gas and the polymer, this is made possible by a material entropy increase from contraction that makes up for the loss of entropy from absorption of the thermal energy, and cooling of the material.</p>
<h2 id="classical-thermodynamics-vs.-statistical-thermodynamics">Classical thermodynamics vs. statistical thermodynamics</h2>
<p>As an example, from a <a href="classical_thermodynamics" title="wikilink">classical thermodynamics</a> point of view one might ask what is it about a <a href="thermodynamic_system" title="wikilink">thermodynamic system</a> of gas molecules, such as <a href="ammonia" class="uri" title="wikilink">ammonia</a> NH<sub>3</sub>, that determines the <a href="thermodynamic_free_energy" title="wikilink">free energy</a> characteristic of that compound? Classical thermodynamics does not provide the answer. If, for example, we were given spectroscopic data, of this body of gas molecules, such as <a href="bond_length" title="wikilink">bond length</a>, <a href="bond_angle" title="wikilink">bond angle</a>, <a href="bond_rotation" title="wikilink">bond rotation</a>, and flexibility of the bonds in NH<sub>3</sub> we should see that the free energy could not be other than it is. To prove this true, we need to bridge the gap between the microscopic realm of atoms and molecules and the macroscopic realm of classical thermodynamics. From physics, statistical mechanics provides such a bridge by teaching us how to conceive of a thermodynamic <em>system</em> as an assembly of <em>units</em>. More specifically, it demonstrates how the <a href="thermodynamic_parameters" title="wikilink">thermodynamic parameters</a> of a system, such as temperature and pressure, are interpretable in terms of the parameters descriptive of such constituent atoms and molecules.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></p>
<p>In a bounded system, the crucial characteristic of these microscopic units is that their energies are <a href="quantization_(physics)" title="wikilink">quantized</a>. That is, where the energies accessible to a macroscopic system form a virtual continuum of possibilities, the energies open to any of its submicroscopic components are limited to a discontinuous set of alternatives associated with integral values of some <a href="quantum_number" title="wikilink">quantum number</a>.</p>
<h2 id="see-also">See also</h2>

<ul>
<li><a href="Chemical_thermodynamics" title="wikilink">Chemical thermodynamics</a></li>
<li><a href="Configuration_entropy" title="wikilink">Configuration entropy</a></li>
<li><a href="Dangerously_irrelevant" title="wikilink">Dangerously irrelevant</a></li>
<li><a href="Paul_Ehrenfest" title="wikilink">Paul Ehrenfest</a></li>
<li><a href="Equilibrium_thermodynamics" title="wikilink">Equilibrium thermodynamics</a></li>
<li><a href="Fluctuation_dissipation_theorem" title="wikilink">Fluctuation dissipation theorem</a></li>
<li><a href="List_of_publications_in_physics#Statistical_mechanics" title="wikilink">Important Publications in Statistical Mechanics</a></li>
<li><a href="Ising_Model" title="wikilink">Ising Model</a></li>
<li><a href="List_of_software_for_Monte_Carlo_molecular_modeling" title="wikilink">List of software for Monte Carlo molecular modeling</a></li>
<li><a href="Maxwell&#39;s_demon" title="wikilink">Maxwell's demon</a></li>
<li><a href="Mean_field_theory" title="wikilink">Mean field theory</a></li>
<li><a href="Nanomechanics" class="uri" title="wikilink">Nanomechanics</a></li>
<li><a href="Non-equilibrium_thermodynamics" title="wikilink">Non-equilibrium thermodynamics</a></li>
<li><a href="Quantum_thermodynamics" title="wikilink">Quantum thermodynamics</a></li>
<li><a href="Statistical_physics" title="wikilink">Statistical physics</a></li>
<li><a href="Thermochemistry" class="uri" title="wikilink">Thermochemistry</a></li>
<li><a href="Widom_insertion_method" title="wikilink">Widom insertion method</a></li>
<li><a href="Monte_Carlo_method" title="wikilink">Monte Carlo method</a></li>
<li><a href="Molecular_modelling" title="wikilink">Molecular modelling</a></li>
<li><a href="Parallel_tempering" title="wikilink">Parallel tempering</a></li>
</ul>

<dl>

<dd>{| class=&quot;wikitable&quot; border-color:#ccc&quot;
</dd>
</dl>
<p>|+ <strong>A Table of Statistical Mechanics Articles</strong> |- ! align=&quot;center&quot; | ! align=&quot;center&quot; |Maxwell-Boltzmann ! align=&quot;center&quot; |Bose-Einstein ! align=&quot;center&quot; |Fermi-Dirac |- ! align=&quot;center&quot; |Particle | align=&quot;center&quot; | | align=&quot;center&quot; |<a href="Boson" class="uri" title="wikilink">Boson</a> | align=&quot;center&quot; |<a href="Fermion" class="uri" title="wikilink">Fermion</a> |- ! align=&quot;center&quot; |Statistics | align=&quot;center&quot; colspan=3 | <a href="Partition_function_(statistical_mechanics)" title="wikilink">Partition function</a><br />
<a href="Identical_particles#Statistical_properties" title="wikilink">Statistical properties</a><br />
<a href="Microcanonical_ensemble" title="wikilink">Microcanonical ensemble</a> | <a href="Canonical_ensemble" title="wikilink">Canonical ensemble</a> | <a href="Grand_canonical_ensemble" title="wikilink">Grand canonical ensemble</a> |- ! align=&quot;center&quot; |Statistics | align=&quot;center&quot; | <a href="Maxwell-Boltzmann_statistics" title="wikilink">Maxwell-Boltzmann statistics</a><br />
<a href="Maxwell-Boltzmann_distribution" title="wikilink">Maxwell-Boltzmann distribution</a><br />
<a href="Boltzmann_distribution" title="wikilink">Boltzmann distribution</a><br />
<a href="Gibbs_paradox" title="wikilink">Gibbs paradox</a> | align=&quot;center&quot; |<a href="Bose-Einstein_statistics" title="wikilink">Bose-Einstein statistics</a> | align=&quot;center&quot; |<a href="Fermi-Dirac_statistics" title="wikilink">Fermi-Dirac statistics</a> |- ! align=&quot;center&quot; | Thomas-Fermi<br />
approximation | align=&quot;center&quot; colspan=3 | <a href="gas_in_a_box" title="wikilink">gas in a box</a><br />
<a href="gas_in_a_harmonic_trap" title="wikilink">gas in a harmonic trap</a> |- ! align=&quot;center&quot; |Gas | align=&quot;center&quot; |<a href="Ideal_gas" title="wikilink">Ideal gas</a> | align=&quot;center&quot; | <a href="Bose_gas" title="wikilink">Bose gas</a><br />
<a href="Debye_model" title="wikilink">Debye model</a><br />
<a href="Bose-Einstein_condensate" title="wikilink">Bose-Einstein condensate</a><br />
<a href="Planck&#39;s_law_of_black_body_radiation" title="wikilink">Planck's law of black body radiation</a> | align=&quot;center&quot; | <a href="Fermi_gas" title="wikilink">Fermi gas</a><br />
<a href="Fermion_condensate" title="wikilink">Fermion condensate</a> |- ! align=&quot;center&quot; | Chemical<br />
Equilibrium | align=&quot;center&quot; | Classical <a href="Chemical_equilibrium" title="wikilink">Chemical equilibrium</a> | align=&quot;center&quot; colspan=2| |}</p>
<h2 id="notes">Notes</h2>

<h2 id="references">References</h2>

<dl>
<dt>Bibliography</dt>

</dl>
<ul>
<li></li>
</ul>
<h2 id="further-reading">Further reading</h2>
<ul>
<li><a href="List_of_notable_textbooks_in_statistical_mechanics" title="wikilink">List of notable textbooks in statistical mechanics</a></li>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
<li><p>ISBN 978-981-270-707-9</p></li>
<li><p>ISBN 978-3-8171-3286-7</p></li>
<li><p>translated by Stephen G. Brush (1964) Berkeley: University of California Press; (1995) New York: Dover ISBN 0-486-68455-5</p></li>
<li></li>
<li><p>Translated by J.B. Sykes and M.J. Kearsley</p></li>
<li></li>
<li></li>
</ul>
<h2 id="external-links">External links</h2>
<ul>
<li><a href="http://plato.stanford.edu/entries/statphys-statmech/">Philosophy of Statistical Mechanics</a> article by Lawrence Sklar for the <a href="Stanford_Encyclopedia_of_Philosophy" title="wikilink">Stanford Encyclopedia of Philosophy</a>.</li>
<li><a href="http://www.sklogwiki.org/">Sklogwiki - Thermodynamics, statistical mechanics, and the computer simulation of materials.</a> SklogWiki is particularly orientated towards liquids and soft condensed matter.</li>
<li><a href="http://history.hyperjeff.net/statmech.html">Statistical Thermodynamics</a> - Historical Timeline</li>
<li><a href="http://farside.ph.utexas.edu/teaching/sm1/statmech.pdf">Thermodynamics and Statistical Mechanics</a> by Richard Fitzpatrick</li>
<li><a href="http://arxiv.org/abs/1107.0568">Lecture Notes in Statistical Mechanics and Mesoscopics</a> by Doron Cohen</li>
</ul>



<p><a href="ar:&lt;U+0645&gt;&lt;U+064A&gt;&lt;U+0643&gt;&lt;U+0627&gt;&lt;U+0646&gt;&lt;U+064A&gt;&lt;U+0643&gt;&lt;U+0627&gt;_&lt;U+0625&gt;&lt;U+062D&gt;&lt;U+0635&gt;&lt;U+0627&gt;&lt;U+0626&gt;&lt;U+064A&gt;&lt;U+0629&gt;" title="wikilink">ar:&lt;U+0645&gt;&lt;U+064A&gt;&lt;U+0643&gt;&lt;U+0627&gt;&lt;U+0646&gt;&lt;U+064A&gt;&lt;U+0643&gt;&lt;U+0627&gt; &lt;U+0625&gt;&lt;U+062D&gt;&lt;U+0635&gt;&lt;U+0627&gt;&lt;U+0626&gt;&lt;U+064A&gt;&lt;U+0629&gt;</a> <a href="as:&lt;U+09AA&gt;&lt;U+09F0&gt;&lt;U+09BF&gt;&lt;U+09B8&gt;&lt;U+09BE&gt;&lt;U+0982&gt;&lt;U+0996&gt;&lt;U+09CD&gt;&lt;U+09AF&gt;&lt;U+09BF&gt;&lt;U+0995&gt;_&lt;U+09AC&gt;&lt;U+09B2&gt;_&lt;U+09AC&gt;&lt;U+09BF&gt;&lt;U+099C&gt;&lt;U+09CD&gt;&lt;U+099E&gt;&lt;U+09BE&gt;&lt;U+09A8&gt;" title="wikilink">as:&lt;U+09AA&gt;&lt;U+09F0&gt;&lt;U+09BF&gt;&lt;U+09B8&gt;&lt;U+09BE&gt;&lt;U+0982&gt;&lt;U+0996&gt;&lt;U+09CD&gt;&lt;U+09AF&gt;&lt;U+09BF&gt;&lt;U+0995&gt; &lt;U+09AC&gt;&lt;U+09B2&gt; &lt;U+09AC&gt;&lt;U+09BF&gt;&lt;U+099C&gt;&lt;U+09CD&gt;&lt;U+099E&gt;&lt;U+09BE&gt;&lt;U+09A8&gt;</a> <a href="bg:&lt;U+0421&gt;&lt;U+0442&gt;&lt;U+0430&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0441&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0447&gt;&lt;U+0435&gt;&lt;U+0441&gt;&lt;U+043A&gt;&lt;U+0430&gt;_&lt;U+043C&gt;&lt;U+0435&gt;&lt;U+0445&gt;&lt;U+0430&gt;&lt;U+043D&gt;&lt;U+0438&gt;&lt;U+043A&gt;&lt;U+0430&gt;" title="wikilink">bg:&lt;U+0421&gt;&lt;U+0442&gt;&lt;U+0430&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0441&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0447&gt;&lt;U+0435&gt;&lt;U+0441&gt;&lt;U+043A&gt;&lt;U+0430&gt; &lt;U+043C&gt;&lt;U+0435&gt;&lt;U+0445&gt;&lt;U+0430&gt;&lt;U+043D&gt;&lt;U+0438&gt;&lt;U+043A&gt;&lt;U+0430&gt;</a> <a href="ca:Mec&lt;U+00E0&gt;nica_estad&lt;U+00ED&gt;stica" title="wikilink">ca:Mec&lt;U+00E0&gt;nica estad&lt;U+00ED&gt;stica</a> <a href="cy:Mecaneg_ystadegol" title="wikilink">cy:Mecaneg ystadegol</a> <a href="de:Statistische_Mechanik" title="wikilink">de:Statistische Mechanik</a> <a href="el:&lt;U+03A3&gt;&lt;U+03C4&gt;&lt;U+03B1&gt;&lt;U+03C4&gt;&lt;U+03B9&gt;&lt;U+03C3&gt;&lt;U+03C4&gt;&lt;U+03B9&gt;&lt;U+03BA&gt;&lt;U+03AE&gt;_&lt;U+03BC&gt;&lt;U+03B7&gt;&lt;U+03C7&gt;&lt;U+03B1&gt;&lt;U+03BD&gt;&lt;U+03B9&gt;&lt;U+03BA&gt;&lt;U+03AE&gt;" title="wikilink">el:&lt;U+03A3&gt;&lt;U+03C4&gt;&lt;U+03B1&gt;&lt;U+03C4&gt;&lt;U+03B9&gt;&lt;U+03C3&gt;&lt;U+03C4&gt;&lt;U+03B9&gt;&lt;U+03BA&gt;&lt;U+03AE&gt; &lt;U+03BC&gt;&lt;U+03B7&gt;&lt;U+03C7&gt;&lt;U+03B1&gt;&lt;U+03BD&gt;&lt;U+03B9&gt;&lt;U+03BA&gt;&lt;U+03AE&gt;</a> <a href="es:F&lt;U+00ED&gt;sica_estad&lt;U+00ED&gt;stica" title="wikilink">es:F&lt;U+00ED&gt;sica estad&lt;U+00ED&gt;stica</a> <a href="fa:&lt;U+0645&gt;&lt;U+06A9&gt;&lt;U+0627&gt;&lt;U+0646&gt;&lt;U+06CC&gt;&lt;U+06A9&gt;_&lt;U+0622&gt;&lt;U+0645&gt;&lt;U+0627&gt;&lt;U+0631&gt;&lt;U+06CC&gt;" title="wikilink">fa:&lt;U+0645&gt;&lt;U+06A9&gt;&lt;U+0627&gt;&lt;U+0646&gt;&lt;U+06CC&gt;&lt;U+06A9&gt; &lt;U+0622&gt;&lt;U+0645&gt;&lt;U+0627&gt;&lt;U+0631&gt;&lt;U+06CC&gt;</a> <a href="fr:Physique_statistique" title="wikilink">fr:Physique statistique</a> <a href="gl:Mec&lt;U+00E1&gt;nica_estat&lt;U+00ED&gt;stica" title="wikilink">gl:Mec&lt;U+00E1&gt;nica estat&lt;U+00ED&gt;stica</a> <a href="ko:&lt;U+D1B5&gt;&lt;U+ACC4&gt;&lt;U+C5ED&gt;&lt;U+D559&gt;" class="uri" title="wikilink">ko:&lt;U+D1B5&gt;&lt;U+ACC4&gt;&lt;U+C5ED&gt;&lt;U+D559&gt;</a> <a href="hr:Statisti&lt;U+010D&gt;ka_mehanika" title="wikilink">hr:Statisti&lt;U+010D&gt;ka mehanika</a> <a href="id:Mekanika_statistika" title="wikilink">id:Mekanika statistika</a> <a href="is:Safne&lt;U+00F0&gt;lisfr&lt;U+00E6&gt;&lt;U+00F0&gt;i" class="uri" title="wikilink">is:Safne&lt;U+00F0&gt;lisfr&lt;U+00E6&gt;&lt;U+00F0&gt;i</a> <a href="it:Meccanica_statistica" title="wikilink">it:Meccanica statistica</a> <a href="he:&lt;U+05E4&gt;&lt;U+05D9&gt;&lt;U+05D6&gt;&lt;U+05D9&gt;&lt;U+05E7&gt;&lt;U+05D4&gt;_&lt;U+05E1&gt;&lt;U+05D8&gt;&lt;U+05D8&gt;&lt;U+05D9&gt;&lt;U+05E1&gt;&lt;U+05D8&gt;&lt;U+05D9&gt;&lt;U+05EA&gt;" title="wikilink">he:&lt;U+05E4&gt;&lt;U+05D9&gt;&lt;U+05D6&gt;&lt;U+05D9&gt;&lt;U+05E7&gt;&lt;U+05D4&gt; &lt;U+05E1&gt;&lt;U+05D8&gt;&lt;U+05D8&gt;&lt;U+05D9&gt;&lt;U+05E1&gt;&lt;U+05D8&gt;&lt;U+05D9&gt;&lt;U+05EA&gt;</a> <a href="kk:&lt;U+0421&gt;&lt;U+0442&gt;&lt;U+0430&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0441&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+043A&gt;&lt;U+0430&gt;&lt;U+043B&gt;&lt;U+044B&gt;&lt;U+049B&gt;_&lt;U+043C&gt;&lt;U+0435&gt;&lt;U+0445&gt;&lt;U+0430&gt;&lt;U+043D&gt;&lt;U+0438&gt;&lt;U+043A&gt;&lt;U+0430&gt;" title="wikilink">kk:&lt;U+0421&gt;&lt;U+0442&gt;&lt;U+0430&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0441&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+043A&gt;&lt;U+0430&gt;&lt;U+043B&gt;&lt;U+044B&gt;&lt;U+049B&gt; &lt;U+043C&gt;&lt;U+0435&gt;&lt;U+0445&gt;&lt;U+0430&gt;&lt;U+043D&gt;&lt;U+0438&gt;&lt;U+043A&gt;&lt;U+0430&gt;</a> <a href="hu:Statisztikus_mechanika" title="wikilink">hu:Statisztikus mechanika</a> <a href="ml:&lt;U+0D38&gt;&lt;U+0D3E&gt;&lt;U+0D02&gt;&lt;U+0D16&gt;&lt;U+0D4D&gt;&lt;U+0D2F&gt;&lt;U+0D3F&gt;&lt;U+0D15&gt;&lt;U+0D2C&gt;&lt;U+0D32&gt;&lt;U+0D24&gt;&lt;U+0D28&gt;&lt;U+0D4D&gt;&lt;U+0D24&gt;&lt;U+0D4D&gt;&lt;U+0D30&gt;&lt;U+0D02&gt;" class="uri" title="wikilink">ml:&lt;U+0D38&gt;&lt;U+0D3E&gt;&lt;U+0D02&gt;&lt;U+0D16&gt;&lt;U+0D4D&gt;&lt;U+0D2F&gt;&lt;U+0D3F&gt;&lt;U+0D15&gt;&lt;U+0D2C&gt;&lt;U+0D32&gt;&lt;U+0D24&gt;&lt;U+0D28&gt;&lt;U+0D4D&gt;&lt;U+0D24&gt;&lt;U+0D4D&gt;&lt;U+0D30&gt;&lt;U+0D02&gt;</a> <a href="ms:Mekanik_statistik" title="wikilink">ms:Mekanik statistik</a> <a href="nl:Statistische_thermodynamica" title="wikilink">nl:Statistische thermodynamica</a> <a href="ja:&lt;U+7D71&gt;&lt;U+8A08&gt;&lt;U+529B&gt;&lt;U+5B66&gt;" class="uri" title="wikilink">ja:&lt;U+7D71&gt;&lt;U+8A08&gt;&lt;U+529B&gt;&lt;U+5B66&gt;</a> <a href="nn:Statistisk_mekanikk" title="wikilink">nn:Statistisk mekanikk</a> <a href="pl:Mechanika_statystyczna" title="wikilink">pl:Mechanika statystyczna</a> <a href="pt:Mec&lt;U+00E2&gt;nica_estat&lt;U+00ED&gt;stica" title="wikilink">pt:Mec&lt;U+00E2&gt;nica estat&lt;U+00ED&gt;stica</a> <a href="ro:Mecanic&lt;U+0103&gt;_statistic&lt;U+0103&gt;" title="wikilink">ro:Mecanic&lt;U+0103&gt; statistic&lt;U+0103&gt;</a> <a href="ru:&lt;U+0421&gt;&lt;U+0442&gt;&lt;U+0430&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0441&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0447&gt;&lt;U+0435&gt;&lt;U+0441&gt;&lt;U+043A&gt;&lt;U+0430&gt;&lt;U+044F&gt;_&lt;U+043C&gt;&lt;U+0435&gt;&lt;U+0445&gt;&lt;U+0430&gt;&lt;U+043D&gt;&lt;U+0438&gt;&lt;U+043A&gt;&lt;U+0430&gt;" title="wikilink">ru:&lt;U+0421&gt;&lt;U+0442&gt;&lt;U+0430&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0441&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0447&gt;&lt;U+0435&gt;&lt;U+0441&gt;&lt;U+043A&gt;&lt;U+0430&gt;&lt;U+044F&gt; &lt;U+043C&gt;&lt;U+0435&gt;&lt;U+0445&gt;&lt;U+0430&gt;&lt;U+043D&gt;&lt;U+0438&gt;&lt;U+043A&gt;&lt;U+0430&gt;</a> <a href="sq:Mekanika_statistike" title="wikilink">sq:Mekanika statistike</a> <a href="sl:Statisti&lt;U+010D&gt;na_mehanika" title="wikilink">sl:Statisti&lt;U+010D&gt;na mehanika</a> <a href="sr:&lt;U+0421&gt;&lt;U+0442&gt;&lt;U+0430&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0441&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0447&gt;&lt;U+043A&gt;&lt;U+0430&gt;_&lt;U+043C&gt;&lt;U+0435&gt;&lt;U+0445&gt;&lt;U+0430&gt;&lt;U+043D&gt;&lt;U+0438&gt;&lt;U+043A&gt;&lt;U+0430&gt;" title="wikilink">sr:&lt;U+0421&gt;&lt;U+0442&gt;&lt;U+0430&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0441&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0447&gt;&lt;U+043A&gt;&lt;U+0430&gt; &lt;U+043C&gt;&lt;U+0435&gt;&lt;U+0445&gt;&lt;U+0430&gt;&lt;U+043D&gt;&lt;U+0438&gt;&lt;U+043A&gt;&lt;U+0430&gt;</a> <a href="sv:Statistisk_mekanik" title="wikilink">sv:Statistisk mekanik</a> <a href="tr:&lt;U+0130&gt;statistiksel_mekanik" title="wikilink">tr:&lt;U+0130&gt;statistiksel mekanik</a> <a href="uk:&lt;U+0421&gt;&lt;U+0442&gt;&lt;U+0430&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0441&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0447&gt;&lt;U+043D&gt;&lt;U+0430&gt;_&lt;U+043C&gt;&lt;U+0435&gt;&lt;U+0445&gt;&lt;U+0430&gt;&lt;U+043D&gt;&lt;U+0456&gt;&lt;U+043A&gt;&lt;U+0430&gt;" title="wikilink">uk:&lt;U+0421&gt;&lt;U+0442&gt;&lt;U+0430&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0441&gt;&lt;U+0442&gt;&lt;U+0438&gt;&lt;U+0447&gt;&lt;U+043D&gt;&lt;U+0430&gt; &lt;U+043C&gt;&lt;U+0435&gt;&lt;U+0445&gt;&lt;U+0430&gt;&lt;U+043D&gt;&lt;U+0456&gt;&lt;U+043A&gt;&lt;U+0430&gt;</a> <a href="vi:C&lt;U+01A1&gt;_h&lt;U+1ECD&gt;c_th&lt;U+1ED1&gt;ng_k&lt;U+00EA&gt;" title="wikilink">vi:C&lt;U+01A1&gt; h&lt;U+1ECD&gt;c th&lt;U+1ED1&gt;ng k&lt;U+00EA&gt;</a> <a href="zh:&lt;U+7EDF&gt;&lt;U+8BA1&gt;&lt;U+529B&gt;&lt;U+5B66&gt;" class="uri" title="wikilink">zh:&lt;U+7EDF&gt;&lt;U+8BA1&gt;&lt;U+529B&gt;&lt;U+5B66&gt;</a></p>
<p><a href="Category:Concepts_in_physics" title="wikilink">Category:Concepts in physics</a> <a href="Category:Physics" class="uri" title="wikilink">Category:Physics</a> <a href="Category:Statistical_mechanics" title="wikilink">*</a> <a href="Category:Thermodynamics" class="uri" title="wikilink">Category:Thermodynamics</a></p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1">The terms <em>statistical mechanics</em> and <em>statistical thermodynamics</em> are used interchangeably. <em><a href="Statistical_physics" title="wikilink">Statistical physics</a></em> is a broader term which includes statistical mechanics, but is sometimes also used as a synonym for statistical mechanics<a href="#fnref1" class="footnote-back">↩</a></li>
<li id="fn2"> (section 1.2)<a href="#fnref2" class="footnote-back">↩</a></li>
<li id="fn3"><a href="#fnref3" class="footnote-back">↩</a></li>
<li id="fn4"><a href="#fnref4" class="footnote-back">↩</a></li>
<li id="fn5"><a href="#fnref5" class="footnote-back">↩</a></li>
<li id="fn6"><a href="#fnref6" class="footnote-back">↩</a></li>
<li id="fn7">Srednicki, Mark. &quot;Chaos and Quantum Thermalization.&quot; <a href="http://pre.aps.org/abstract/PRE/v50/i2/p888_1">Physical Review E 50 (1994) 888</a>. <em>ArXiv pre-print</em>: <a href="http://arxiv.org/abs/cond-mat/9403051">cond-mat/9403051</a><a href="#fnref7" class="footnote-back">↩</a></li>
<li id="fn8">Srednicki, Mark. &quot;Thermal Fluctuations in Quantized Chaotic Systems.&quot; <a href="http://iopscience.iop.org/0305-4470/29/4/003/">Journal of Physics A29 (1996) L75-L79</a>. <em>ArXiv pre-print</em>: <a href="http://arxiv.org/abs/chao-dyn/9511001">chao-dyn/9511001</a><a href="#fnref8" class="footnote-back">↩</a></li>
<li id="fn9">Jarzynski, C. &quot; Berry&lt;U+2019&gt;s conjecture and information theory.&quot; <a href="http://pre.aps.org/abstract/PRE/v56/i2/p2254_1">Physical Review E 56, 2254 (1997)</a>. <em>ArXiv pre-print</em>: <a href="http://arxiv.org/abs/chao-dyn/9703014">chao-dyn/9703014</a><a href="#fnref9" class="footnote-back">↩</a></li>
<li id="fn10">see also the detailed explanation in <a href="http://clesm.mae.ufl.edu/wiki.pub/index.php/Configuration_integral_%28statistical_mechanics%29">configuration integral</a><a href="#fnref10" class="footnote-back">↩</a></li>
<li id="fn11"><a href="#fnref11" class="footnote-back">↩</a></li>
</ol>
</section>
