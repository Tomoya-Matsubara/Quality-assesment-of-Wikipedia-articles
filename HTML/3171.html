

<p>[[Image:Components stress tensor cartesian.svg|300px|right|thumb|Stress, a second-order tensor. The tensor's components, in a three-dimensional Cartesian coordinate system, form the matrix</p>
<p><span class="math inline">$\scriptstyle\sigma = \begin{bmatrix}\mathbf{T}^{(\mathbf{e}_1)} \mathbf{T}^{(\mathbf{e}_2)} \mathbf{T}^{(\mathbf{e}_3)}\end{bmatrix} = \begin{bmatrix} \sigma_{11} &amp; \sigma_{12} &amp; \sigma_{13} \\ \sigma_{21} &amp; \sigma_{22} &amp; \sigma_{23} \\ \sigma_{31} &amp; \sigma_{32} &amp; \sigma_{33} \end{bmatrix}$</span></p>
<p>whose columns are the forces acting on the <span class="math inline"><strong>e</strong><sub>1</sub></span>, <span class="math inline"><strong>e</strong><sub>2</sub></span>, and <span class="math inline"><strong>e</strong><sub>3</sub></span> faces of the cube.]]</p>
<p><strong>Tensors</strong> are <a href="geometry" title="wikilink">geometric</a> entities introduced into <a href="mathematics" class="uri" title="wikilink">mathematics</a> and <a href="physics" class="uri" title="wikilink">physics</a> to extend the notion of <a href="Scalar_(mathematics)" title="wikilink">scalars</a>, <a href="Euclidean_vectors" title="wikilink">geometric vectors</a>, and <a href="Matrix_(mathematics)" title="wikilink">matrices</a> to higher orders. Tensors were first conceived by <a href="Tullio_Levi-Civita" title="wikilink">Tullio Levi-Civita</a> and <a href="Gregorio_Ricci-Curbastro" title="wikilink">Gregorio Ricci-Curbastro</a>, who continued the earlier work of <a href="Bernhard_Riemann" title="wikilink">Bernhard Riemann</a> and <a href="Elwin_Bruno_Christoffel" title="wikilink">Elwin Bruno Christoffel</a> and others, as part of the <em>absolute differential calculus</em>. The concept enabled an alternative formulation of the intrinsic <a href="differential_geometry" title="wikilink">differential geometry</a> of a <a href="manifold" class="uri" title="wikilink">manifold</a> in the form of the <a href="Riemann_curvature_tensor" title="wikilink">Riemann curvature tensor</a>.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a></p>
<p>Many physical quantities are naturally regarded not as vectors themselves, but as correspondences between one set of vectors and another. For example, the <a href="Stress_(mechanics)#Cauchy&lt;U+2019&gt;s_stress_theorem_&lt;U+2013&gt;_stress_tensor" title="wikilink">stress tensor</a> <strong>T</strong> takes a direction <strong>v</strong> as input and produces the stress <strong>T</strong><sup>(<em>v</em>)</sup> on the surface normal to this vector as output and so expresses a relationship between these two vectors. Because they express a relationship between vectors, tensors themselves are <a href="coordinate-free" title="wikilink">independent of a particular choice</a> of <a href="coordinate_system" title="wikilink">coordinate system</a>. It is possible to represent a tensor by examining what it does to a coordinate <a href="basis_of_a_vector_space" title="wikilink">basis</a> or <a href="frame_of_reference" title="wikilink">frame of reference</a>; the resulting quantity is then an organized <a href="Array_data_structure#Multidimensional_arrays" title="wikilink">multi-dimensional array</a> of numerical values. The coordinate-independence of a tensor then takes the form of a <a href="covariant_transformation" title="wikilink">&quot;covariant&quot; transformation law</a> that relates the array computed in one coordinate system to that computed in another one.</p>
<p>The order (or degree) of a tensor is the dimensionality of the array needed to represent it. A number is a 0-dimensional array, so it is sufficient to represent a scalar, a 0th-order tensor. A <a href="coordinate_vector" title="wikilink">coordinate vector</a>, or 1-dimensional array, can represent a vector, a 1st-order tensor. A 2-dimensional array, or square <a href="matrix_(mathematics)" title="wikilink">matrix</a>, is then needed to represent a 2nd-order tensor. In general, an order-<em>k</em> tensor can be represented as a <em>k</em>-dimensional array of components. The order of a tensor is the number of indices necessary to refer unambiguously to an individual component of a tensor.</p>
<h2 id="history">History</h2>
<p>The concepts of later tensor analysis arose from the work of <a href="C._F._Gauss" title="wikilink">C. F. Gauss</a> in differential geometry, and the formulation was much influenced by the theory of <a href="algebraic_form" title="wikilink">algebraic forms</a> and invariants developed in the middle of the nineteenth century.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> The word &quot;tensor&quot; itself was introduced in 1846 by <a href="William_Rowan_Hamilton" title="wikilink">William Rowan Hamilton</a><a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> to describe something different from what is now meant by a tensor.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a> The contemporary usage was brought in by <a href="Woldemar_Voigt" title="wikilink">Woldemar Voigt</a> in 1898.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a></p>
<p>Tensor calculus was developed around 1890 by <a href="Gregorio_Ricci-Curbastro" title="wikilink">Gregorio Ricci-Curbastro</a> (also called just Ricci) under the title <em>absolute differential calculus</em>, and originally presented by Ricci in 1892.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> It was made accessible to many mathematicians by the publication of Ricci and <a href="Tullio_Levi-Civita" title="wikilink">Tullio Levi-Civita</a>'s 1900 classic text <em>M&lt;U+00E9&gt;thodes de calcul diff&lt;U+00E9&gt;rentiel absolu et leurs applications</em> (Methods of absolute differential calculus and their applications)  (in French; translations followed).</p>
<p>In the 20th century, the subject came to be known as <em>tensor analysis</em>, and achieved broader acceptance with the introduction of <a href="Albert_Einstein" title="wikilink">Einstein</a>'s theory of <a href="general_relativity" title="wikilink">general relativity</a>, around 1915. General relativity is formulated completely in the language of tensors. Einstein had learned about them, with great difficulty, from the geometer <a href="Marcel_Grossmann" title="wikilink">Marcel Grossmann</a>.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> Levi-Civita then initiated a correspondence with Einstein to correct mistakes Einstein had made in his use of tensor analysis. The correspondence lasted 1915&lt;U+2013&gt;17, and was characterized by mutual respect, with Einstein at one point writing:<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a></p>

<p>Tensors were also found to be useful in other fields such as <a href="continuum_mechanics" title="wikilink">continuum mechanics</a>. Some well-known examples of tensors in <a href="differential_geometry" title="wikilink">differential geometry</a> are <a href="quadratic_form" title="wikilink">quadratic forms</a> such as <a href="metric_tensor" title="wikilink">metric tensors</a>, and the <a href="Riemann_curvature_tensor" title="wikilink">Riemann curvature tensor</a>. The <a href="exterior_algebra" title="wikilink">exterior algebra</a> of <a href="Hermann_Grassmann" title="wikilink">Hermann Grassmann</a>, from the middle of the nineteenth century, is itself a tensor theory, and highly geometric, but it was some time before it was seen, with the theory of <a href="differential_form" title="wikilink">differential forms</a>, as naturally unified with tensor calculus. The work of <a href="&lt;U+00C9&gt;lie_Cartan" title="wikilink">&lt;U+00C9&gt;lie Cartan</a> made differential forms one of the basic kinds of tensor fields used in mathematics.</p>
<p>From about the 1920s onwards, it was realised that tensors play a basic role in <a href="algebraic_topology" title="wikilink">algebraic topology</a> (for example in the <a href="K&lt;U+00FC&gt;nneth_theorem" title="wikilink">K&lt;U+00FC&gt;nneth theorem</a>). Correspondingly there are types of tensors at work in many branches of <a href="abstract_algebra" title="wikilink">abstract algebra</a>, particularly in <a href="homological_algebra" title="wikilink">homological algebra</a> and <a href="representation_theory" title="wikilink">representation theory</a>. Multilinear algebra can be developed in greater generality than for scalars coming from a <a href="field_(mathematics)" title="wikilink">field</a>, but the theory is then certainly less geometric, and computations more technical and less algorithmic. Tensors are generalized within <a href="category_theory" title="wikilink">category theory</a> by means of the concept of <a href="monoidal_category" title="wikilink">monoidal category</a>, from the 1960s.</p>
<h2 id="definition">Definition</h2>
<p>There are several different approaches to defining tensors. Although seemingly different, the approaches just describe the same geometric concept using different languages and at different levels of abstraction.</p>
<h3 id="as-multidimensional-arrays">... as multidimensional arrays</h3>
<p>Just as a scalar is described by a single number and a vector can be described by a list of numbers, tensors in general can be considered as a multidimensional array of numbers, which are known as its &quot;scalar components&quot; or simply &quot;components.&quot; The entries of such an array are symbolically denoted by the name of the tensor with indices giving the position in the array. The total number of indices is equal to the dimension of the array and is called the <em>order</em> or the <em>rank</em> of the tensor.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> For example, the entries (also called <em>components</em>) of an order 2 tensor <em>T</em> would be denoted <em>T</em><sub><em>ij</em></sub>, where <em>i</em> and <em>j</em> are indices running from 1 to the dimension of the related vector space.</p>
<p>Just like the components of a vector change when we change the <a href="basis_(linear_algebra)" title="wikilink">basis</a> of the vector space, the entries of a tensor also change under such a transformation. Recall that the components of a vector can respond in two distinct ways to a change of basis (see <a href="covariance_and_contravariance_of_vectors" title="wikilink">covariance and contravariance of vectors</a>),</p>
<p><br /><span class="math display"><em>ê</em><sub><em>i</em></sub> = ∑<sub><em>j</em></sub><em>R</em><sub><em>i</em></sub><sup><em>j</em></sup><em>e</em><sub><em>j</em></sub> = <em>R</em><sub><em>i</em></sub><sup><em>j</em></sup><em>e</em><sub><em>j</em></sub>,</span><br /> where <em>R</em> is a matrix and in the second expression the summation sign was suppressed (a notational convenience <a href="Einstein_summation_convention" title="wikilink">introduced by Einstein</a> that will be used throughout this article). The components, <em>v</em><sup><em>i</em></sup>, of a regular (or column) vector, <strong>v</strong>, transform with the <a href="matrix_inverse" title="wikilink">inverse</a> of the matrix <em>R</em>,</p>
<p><br /><span class="math display"><em>v̂</em><sup><em>i</em></sup> = (<em>R</em><sup> − 1</sup>)<sub><em>j</em></sub><sup><em>i</em></sup><em>v</em><sup><em>j</em></sup>,</span><br /> where the hat denotes the components in the new basis. While the components, <em>w</em><sub><em>i</em></sub>, of a covector or (row vector), <strong>w</strong> transform with the matrix R itself,</p>
<p><br /><span class="math display"><em>ŵ</em><sub><em>i</em></sub> = <em>R</em><sub><em>i</em></sub><sup><em>j</em></sup><em>w</em><sub><em>j</em></sub>.</span><br /> The components of a tensor transform in a similar manner with a transformation matrix for each index. If an index transforms like a vector with the inverse of the basis transformation, it is called <em>contravariant</em> and is traditionally denoted with an upper index, while an index that transforms with the basis transformation itself is called <em>covariant</em> and is denoted with a lower index. The &quot;transformation law&quot; for a rank <em>m</em> tensor with <em>n</em> contravariant indices and <em>m-n</em> covariant indices is thus given as,</p>
<p><br /><span class="math display"><em>T̂</em><sub><em>i</em><sub><em>n</em> + 1</sub>, …, <em>i</em><sub><em>m</em></sub></sub><sup><em>i</em><sub>1</sub>, …, <em>i</em><sub><em>n</em></sub></sup> = (<em>R</em><sup> − 1</sup>)<sub><em>j</em><sub>1</sub></sub><sup><em>i</em><sub>1</sub></sup>⋯(<em>R</em><sup> − 1</sup>)<sub><em>j</em><sub><em>n</em></sub></sub><sup><em>i</em><sub><em>n</em></sub></sup><em>R</em><sub><em>i</em><sub><em>n</em> + 1</sub></sub><sup><em>j</em><sub><em>n</em> + 1</sub></sup>⋯<em>R</em><sub><em>i</em><sub><em>m</em></sub></sub><sup><em>j</em><sub><em>m</em></sub></sup><em>T</em><sub><em>j</em><sub><em>n</em> + 1</sub>, …, <em>j</em><sub><em>m</em></sub></sub><sup><em>j</em><sub>1</sub>, …, <em>j</em><sub><em>n</em></sub></sup>.</span><br /> Such a tensor is said to be of order or <em>type</em> .<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a></p>
<p>The definition of a tensor as a multidimensional array satisfying a &quot;transformation law&quot; traces back to the work of Ricci.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a> Nowadays, this definition is still popular in physics and engineering text books.<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a><a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a></p>
<h4 id="tensor-fields">Tensor fields</h4>

<p>In many applications, especially in differential geometry and physics, it is natural to consider the components of a tensor to be functions. This was, in fact, the setting of Ricci's original work. In modern mathematical terminology such an object is called a <a href="tensor_field" title="wikilink">tensor field</a>, but they are often simply referred to as tensors themselves.</p>
<p>In this context the defining transformation law takes a different form. The &quot;basis&quot; for the tensor field is determined by the coordinates of the underlying space, and the defining transformation law is expressed in terms of <a href="partial_derivative" title="wikilink">partial derivatives</a> of the coordinate functions, <span class="math inline"><em>x̄</em><sub><em>i</em></sub>(<em>x</em><sub>1</sub>, …, <em>x</em><sub><em>k</em></sub>)</span>, defining a coordinate transformation,</p>
<p><br /><span class="math display">$$\hat{T}^{i_1\dots i_n}_{i_{n+1}\dots i_m}(\bar{x}_1,\ldots,\bar{x}_k) = 
\frac{\partial \bar{x}^{i_1}}{\partial x^{j_1}}
\cdots
\frac{\partial \bar{x}^{i_n}}{\partial x^{j_n}}
\frac{\partial x^{j_{n+1}}}{\partial \bar{x}^{i_{n+1}}}
\cdots
\frac{\partial x^{j_m}}{\partial \bar{x}^{i_m}}
T^{j_1\dots j_n}_{j_{n+1}\dots j_m}(x_1,\ldots,x_k).$$</span><br /></p>
<h3 id="as-multilinear-maps">... as multilinear maps</h3>
<p>A downside to the definition of a tensor using the multidimensional array approach is that it is not apparent from the definition that the defined object is indeed basis independent, as is expected from an intrinsically geometric object. Although it is possible to show that transformation laws indeed ensure independence from the basis, sometimes a more intrinsic definition is preferred. One approach is to define a tensor as a multilinear map. In that approach a type (<em>n</em>,<em>m</em>) tensor <em>T</em> is defined as a map,</p>
<p><br /><span class="math display">$$\begin{matrix} T: &amp; \underbrace{ V^* \times\dots\times V^*} &amp; \times &amp; \underbrace{ V \times\dots\times V} &amp;\rightarrow   \mathbf{R},
\\ &amp; \text{n copies}&amp; &amp;\text{m copies} &amp; &amp; \end{matrix}$$</span><br /> where <em>V</em> is a <a href="vector_space" title="wikilink">vector space</a> and <em>V</em>* is the corresponding <a href="dual_space" title="wikilink">dual space</a> of covectors, which is linear in each of its arguments.</p>
<p>By applying a multilinear map <em>T</em> of type (<em>n</em>,<em>m</em>) to a basis {<em>e</em><sub>j</sub>} for <em>V</em> and a canonical cobasis {<em>&lt;U+03B5&gt;</em><sup>i</sup>} for <em>V</em>*,</p>
<p><br /><span class="math display"><em>T</em><sub><em>j</em><sub>1</sub>…<em>j</em><sub><em>m</em></sub></sub><sup><em>i</em><sub>1</sub>…<em>i</em><sub><em>n</em></sub></sup> ≡ <em>T</em>(<em>ε</em><sup><em>i</em><sub>1</sub></sup>, …, <em>ε</em><sup><em>i</em><sub><em>n</em></sub></sup>, <em>e</em><sub><em>j</em><sub>1</sub></sub>, …, <em>e</em><sub><em>j</em><sub><em>m</em></sub></sub>),</span><br /> a <em>n</em>+<em>m</em> dimensional array of components can be obtained. A different choice of basis will yield different components. But, because <em>T</em> is linear in all of its arguments, the components satisfy the tensor transformation law used in the multilinear array definition. The multidimensional array of components of <em>T</em> thus form a tensor according to that definition. Moreover, such an array can be realised as the components of some multilinear map <em>T</em>. This motivates viewing multilinear maps as the intrinsic objects underlying tensors.</p>
<p>This approach, defining tensors as multilinear maps, is popular in modern differential geometry textbooks<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a> and more mathematically inclined physics textbooks.<a href="#fn15" class="footnote-ref" id="fnref15"><sup>15</sup></a></p>
<h3 id="using-tensor-products">... using tensor products</h3>

<p>For some mathematical applications, a more abstract approach is sometimes useful. This can be achieved by defining tensors in terms of elements of <a href="tensor_product" title="wikilink">tensor products</a> of vector spaces, which in turn are defined through a <a href="universal_property" title="wikilink">universal property</a>. A type (<em>n</em>,<em>m</em>) tensor is defined in this context as an element of the tensor product of vector spaces,<a href="#fn16" class="footnote-ref" id="fnref16"><sup>16</sup></a></p>
<p><br /><span class="math display">$$\begin{matrix} T\in &amp; \underbrace{V \otimes\dots\otimes V} &amp; \otimes &amp; \underbrace{V^* \otimes\dots\otimes V^*}.
\\ &amp; \text{n copies}&amp; &amp;\text{m copies}  \end{matrix}$$</span><br /></p>
<p>If <em>v</em><sub>i</sub> is a basis of <em>V</em> and <em>w</em><sub>j</sub> is a basis of <em>W</em>, then the tensor product <span class="math inline"><em>V</em> ⊗ <em>W</em></span> has a natural basis <span class="math inline"><em>v</em><sub><em>i</em></sub> ⊗ <em>w</em><sub><em>j</em></sub></span>. The components of a tensor <em>T</em> are the coefficients of the tensor with respect to the basis obtained from a basis {<em>e</em><sub>i</sub>} for <em>V</em> and its dual {<em>&lt;U+03B5&gt;</em><sup>j</sup>}, i.e.</p>
<p><br /><span class="math display"><em>T</em> = <em>T</em><sub><em>j</em><sub>1</sub>…<em>j</em><sub><em>m</em></sub></sub><sup><em>i</em><sub>1</sub>…<em>i</em><sub><em>n</em></sub></sup> <em>e</em><sub><em>i</em><sub>1</sub></sub> ⊗ ⋯ ⊗ <em>e</em><sub><em>i</em><sub><em>n</em></sub></sub> ⊗ <em>ε</em><sup><em>j</em><sub>1</sub></sup> ⊗ ⋯ ⊗ <em>ε</em><sup><em>j</em><sub><em>m</em></sub></sup>.</span><br /> Using the properties of the tensor product, it can be shown that these components satisfy the transformation law for a type (<em>m</em>,<em>n</em>) tensor. Moreover, the universal property of the tensor product gives a <a href="bijection" title="wikilink">1-to-1 correspondence</a> between tensors defined in this way and tensors defined as multilinear maps.</p>
<h2 id="notation">Notation</h2>
<h3 id="einstein-notation">Einstein notation</h3>

<p>Einstein notation is a convention for writing tensors that dispenses with writing <a href="summation_sign" title="wikilink">summation signs</a> by leaving them implicit. It relies on the idea that any repeated index is summed over: if the index <em>i</em> is used twice in a given term of a tensor expression, it means that the values are to be summed over <em>i</em>. Several distinct pairs of indices may be summed this way, but commonly only when each index has the same range, so all the omitted summations are sums from 1 to <em>N</em> for some given <em>N</em>.</p>
<h3 id="abstract-index-notation">Abstract index notation</h3>

<p>The abstract index notation is a way to write tensors such that the indices are no longer thought of as numerical, but rather are indeterminates. The abstract index notation captures the expressiveness of indices and the basis-independence of index-free notation.</p>
<h2 id="operations">Operations</h2>
<p>There are a number of basic operations that may be conducted on tensors that again produce a tensor. The linear nature of tensor implies that two tensors of the same type may be added together, and that tensors may be multiplied by a scalar with results analogous to the <a href="Scalar_multiplication" title="wikilink">scaling of a vector</a>. On components, this operations are simply performed component for component. These operations do not change the type of the tensor, however there also exist operations that change the type of the tensors.</p>
<h3 id="tensor-product">Tensor product</h3>

<p>The <a href="tensor_product" title="wikilink">tensor product</a> takes two tensors, <em>S</em> and <em>T</em>, and produces a new tensor, <em>S</em> &lt;U+2297&gt; <em>T</em>, whose order is the sum of the orders of the original tensors. When described as multilinear maps, the tensor product simply multiplies the two tensors, i.e.</p>
<p><br /><span class="math display">(<em>S</em> ⊗ <em>T</em>)(<em>v</em><sub>1</sub>, …, <em>v</em><sub><em>n</em></sub>, <em>v</em><sub><em>n</em> + 1</sub>, …, <em>v</em><sub><em>n</em> + <em>m</em></sub>) = <em>S</em>(<em>v</em><sub>1</sub>, …, <em>v</em><sub><em>n</em></sub>)<em>T</em>(<em>v</em><sub><em>n</em> + 1</sub>, …, <em>v</em><sub><em>n</em> + <em>m</em></sub>),</span><br /> which again produces a map that is linear in all its arguments. On components the effect similarly is to multiply the components of the two input tensors, i.e.</p>
<p><br /><span class="math display">(<em>S</em> ⊗ <em>T</em>)<sub><em>j</em><sub>1</sub>…<em>j</em><sub><em>k</em></sub><em>j</em><sub><em>k</em> + 1</sub>…<em>j</em><sub><em>k</em> + <em>n</em></sub></sub><sup><em>i</em><sub>1</sub>…<em>i</em><sub><em>l</em></sub><em>i</em><sub><em>l</em> + 1</sub>…<em>i</em><sub><em>l</em> + <em>m</em></sub></sup> = <em>S</em><sub><em>j</em><sub>1</sub>…<em>j</em><sub><em>k</em></sub></sub><sup><em>i</em><sub>1</sub>…<em>i</em><sub><em>l</em></sub></sup><em>T</em><sub><em>j</em><sub><em>k</em> + 1</sub>…<em>j</em><sub><em>k</em> + <em>n</em></sub></sub><sup><em>i</em><sub><em>l</em> + 1</sub>…<em>i</em><sub><em>l</em> + <em>m</em></sub></sup>,</span><br /> If <em>S</em> is of type (<em>k</em>,<em>l</em>) and <em>T</em> is of type (<em>n</em>,<em>m</em>), then the tensor product <em>S</em> &lt;U+2297&gt; <em>T</em> has type (<em>k</em>+<em>n</em>,<em>l</em>+<em>m</em>).</p>
<h3 id="contraction">Contraction</h3>

<p><a href="Tensor_contraction" title="wikilink">Tensor contraction</a> is an operation that reduces the total order of a tensor by two. More precisely, it reduces a type (<em>n</em>,<em>m</em>) tensor to a type (<em>n</em>-1,<em>m</em>-1) tensor. In terms of components, the operation is achieved by summing over one contravariant and one covariant index of tensor. For example, a (1,1)-tensor <em>T</em><sup>i</sup><sub>j</sub> can be contracted to a scalar through</p>
<p><br /><span class="math display"><em>T</em><sub><em>i</em></sub><sup><em>i</em></sup></span><br />. Where the summation is again implied. When the (1,1)-tensor is interpreted as a linear map, this operation is known as the <a href="trace_(linear_algebra)" title="wikilink">trace</a>.</p>
<p>The contraction is often used in conjunction with the tensor product to contract an index from each tensor.</p>
<p>The contraction can also be understood in terms of the definition of a tensor as an element of a tensor product of copies of the space <em>V</em> with the space <em>V</em><sup>*</sup> by first decomposing the tensor into a linear combination of simple tensors, and then applying a factor from <em>V</em><sup>*</sup> to a factor from <em>V</em>. For example, a tensor</p>
<p><br /><span class="math display"><em>T</em> ∈ <em>V</em> ⊗ <em>V</em> ⊗ <em>V</em><sup>*</sup></span><br /> can be written as a linear combination</p>
<p><br /><span class="math display"><em>T</em> = <em>v</em><sub>1</sub> ⊗ <em>w</em><sub>1</sub> ⊗ <em>α</em><sub>1</sub> + <em>v</em><sub>2</sub> ⊗ <em>w</em><sub>2</sub> ⊗ <em>α</em><sub>2</sub> + ⋯ + <em>v</em><sub><em>N</em></sub> ⊗ <em>w</em><sub><em>N</em></sub> ⊗ <em>α</em><sub><em>N</em></sub>.</span><br /> The contraction of <em>T</em> on the first and last slots is then the vector</p>
<p><br /><span class="math display"><em>α</em><sub>1</sub>(<em>v</em><sub>1</sub>)<em>w</em><sub>1</sub> + <em>α</em><sub>2</sub>(<em>v</em><sub>2</sub>)<em>w</em><sub>2</sub> + ⋯ + <em>α</em><sub><em>N</em></sub>(<em>v</em><sub><em>N</em></sub>)<em>w</em><sub><em>N</em></sub>.</span><br /></p>
<h3 id="raising-or-lowering-an-index">Raising or lowering an index</h3>

<p>When a vector space is equipped with an <a href="inner_product" title="wikilink">inner product</a> (or <em>metric</em> as it often called in this context), there exist operations that convert a contravariant (upper) index into a covariant (lower) index and vice versa. A metric itself is a (symmetric) (0,2)-tensor, it is thus possible to contract an upper index of a tensor with one of lower indices of the metric. This produces a new tensor with the same index structure as the previous, but with lower index in the position of the contracted upper index. This operation is quite graphically known as <em>lowering an index</em>.</p>
<p>Conversely, a metric has an inverse which is a (2,0)-tensor. This inverse metric can be contracted with a lower index to produce an upper index. This operation is called <em>raising an index</em>.</p>
<h2 id="applications">Applications</h2>
<p>Tensors are important in physics and engineering. In the field of <a href="diffusion_tensor_imaging" title="wikilink">diffusion tensor imaging</a>, for instance, a tensor quantity that expresses the differential permeability of organs to water in varying directions is used to produce scans of the <a href="brain" class="uri" title="wikilink">brain</a>; in this technique tensors are in effect made visible. That application is of a tensor of second order. While such uses of tensors are the most frequent, tensors of higher order also matter in many fields.</p>
<h3 id="continuum-mechanics">Continuum mechanics</h3>
<p>Important examples are provided by continuum mechanics. The stresses inside a <a href="solid_body" title="wikilink">solid body</a> or <a href="fluid" class="uri" title="wikilink">fluid</a> are described by a tensor. The <a href="Stress_(mechanics)" title="wikilink">stress tensor</a> and <a href="strain_tensor" title="wikilink">strain tensor</a> are both second order tensors, and are related in a general linear elastic material by a fourth-order <a href="elasticity_tensor" title="wikilink">elasticity tensor</a>. In detail, the tensor quantifying stress in a 3-dimensional solid object has components that can be conveniently represented as a 3&lt;U+00D7&gt;3 array. The three faces of a cube-shaped infinitesimal volume segment of the solid are each subject to some given force. The force's vector components are also three in number. Thus, 3&lt;U+00D7&gt;3, or 9 components are required to describe the stress at this cube-shaped infinitesimal segment. Within the bounds of this solid is a whole mass of varying stress quantities, each requiring 9 quantities to describe. Thus, a second order tensor is needed.</p>
<p>If a particular <a href="surface_element" title="wikilink">surface element</a> inside the material is singled out, the material on one side of the surface will apply a force on the other side. In general, this force will not be orthogonal to the surface, but it will depend on the orientation of the surface in a linear manner. This is described by a tensor of <a href="type_of_a_tensor" title="wikilink">type (2,0)</a>, in <a href="linear_elasticity" title="wikilink">linear elasticity</a>, or more precisely by a tensor field of type (2,0), since the stresses may vary from point to point.</p>
<h3 id="other-examples-from-physics">Other examples from physics</h3>
<p>Common applications include</p>
<ul>
<li><a href="Electromagnetic_tensor" title="wikilink">Electromagnetic tensor</a> (or Faraday's tensor) in <a href="electromagnetism" class="uri" title="wikilink">electromagnetism</a></li>
<li><a href="Finite_deformation_tensors" title="wikilink">Finite deformation tensors</a> for describing deformations and <a href="strain_tensor" title="wikilink">strain tensor</a> for <a href="Strain_(materials_science)" title="wikilink">strain</a> in <a href="continuum_mechanics" title="wikilink">continuum mechanics</a></li>
<li><a href="Permittivity" class="uri" title="wikilink">Permittivity</a> and <a href="electric_susceptibility" title="wikilink">electric susceptibility</a> are tensors in <a href="anisotropic" class="uri" title="wikilink">anisotropic</a> media</li>
<li><a href="Stress-energy_tensor" title="wikilink">Stress-energy tensor</a> in <a href="general_relativity" title="wikilink">general relativity</a>, used to represent <a href="momentum" class="uri" title="wikilink">momentum</a> <a href="flux" title="wikilink">fluxes</a></li>
<li>Spherical tensor operators are the eigenfunctions of the quantum <a href="angular_momentum" title="wikilink">angular momentum</a> operator in <a href="spherical_coordinates" title="wikilink">spherical coordinates</a></li>
<li>Diffusion tensors, the basis of <a href="Diffusion_Tensor_Imaging" title="wikilink">Diffusion Tensor Imaging</a>, represent rates of diffusion in biologic environments</li>
</ul>
<h3 id="applications-of-tensors-of-order-2">Applications of tensors of order &gt; 2</h3>
<p>The concept of a tensor of order two is often conflated with that of a matrix. Tensors of higher order do however capture ideas important in science and engineering, as has been shown successively in numerous areas as they develop. This happens, for instance, in the field of <a href="computer_vision" title="wikilink">computer vision</a>, with the <a href="trifocal_tensor" title="wikilink">trifocal tensor</a> generalizing the <a href="fundamental_matrix_(computer_vision)" title="wikilink">fundamental matrix</a>.</p>
<p>The field of <a href="nonlinear_optics" title="wikilink">nonlinear optics</a> studies the changes to material <a href="Polarization_density#Relation_between_P_and_E_in_various_materials" title="wikilink">polarization density</a> under extreme electric fields. The polarization waves generated are related to the generating <a href="electric_field" title="wikilink">electric fields</a> through the nonlinear susceptibility tensor. If the polarization <strong>P</strong> is not linearly proportional to the electric field <strong>E</strong>, the medium is termed <em>nonlinear</em>. To a good approximation (for sufficiently weak fields, assuming no permanent dipole moments are present), <strong>P</strong> is given by a <a href="Taylor_series" title="wikilink">Taylor series</a> in <strong>E</strong> whose coefficients are the nonlinear susceptibilities:</p>
<p><br /><span class="math display">$$\frac{P_i}{\varepsilon_0} = \sum_j  \chi^{(1)}_{ij} E_j  +  \sum_{jk} \chi_{ijk}^{(2)} E_j E_k + \sum_{jk\ell} \chi_{ijk\ell}^{(3)} E_j E_k E_\ell  + \cdots \!$$</span><br /></p>
<p>Here <span class="math inline"><em>χ</em><sup>(1)</sup></span> is the linear susceptibility, <span class="math inline"><em>χ</em><sup>(2)</sup></span> gives the <a href="Pockels_effect" title="wikilink">Pockels effect</a> and <a href="second_harmonic_generation" title="wikilink">second harmonic generation</a>, and <span class="math inline"><em>χ</em><sup>(3)</sup></span> gives the <a href="Kerr_effect" title="wikilink">Kerr effect</a>. This expansion shows the way higher-order tensors arise naturally in the subject matter.</p>
<h2 id="generalizations">Generalizations</h2>
<h3 id="tensor-densities">Tensor densities</h3>

<p>It is also possible for a <a href="tensor_field" title="wikilink">tensor field</a> to have a &quot;density&quot;. A tensor with density <em>r</em> transforms as an ordinary tensor under coordinate transformations, except that it is also multiplied by the determinant of the <a href="Jacobian_matrix_and_determinant" title="wikilink">Jacobian</a> to the <em>r</em><sup>th</sup> power.<a href="#fn17" class="footnote-ref" id="fnref17"><sup>17</sup></a> Invariantly, in the language of multilinear algebra, one can think of tensor densities as <a href="multilinear_map" title="wikilink">multilinear maps</a> taking their values in a <a href="density_bundle" title="wikilink">density bundle</a> such as the (1-dimensional) space of <em>n</em>-forms (where <em>n</em> is the dimension of the space), as opposed to taking their values in just <strong>R</strong>. Higher &quot;weights&quot; then just correspond to taking additional tensor products with this space in the range.</p>
<p>In the language of <a href="vector_bundle" title="wikilink">vector bundles</a>, the determinant bundle of the <a href="tangent_bundle" title="wikilink">tangent bundle</a> is a <a href="line_bundle" title="wikilink">line bundle</a> that can be used to 'twist' other bundles <em>r</em> times. While locally the more general transformation law can indeed be used to recognise these tensors, there is a global question that arises, reflecting that in the transformation law one may write either the Jacobian determinant, or its absolute value. Non-integral powers of the (positive) transition functions of the bundle of densities make sense, so that the weight of a density, in that sense, is not restricted to integer values.</p>
<p>Restricting to changes of coordinates with positive Jacobian determinant is possible on <a href="orientable_manifold" title="wikilink">orientable manifolds</a>, because there is a consistent global way to eliminate the minus signs; but otherwise the line bundle of densities and the line bundle of <em>n</em>-forms are distinct. For more on the intrinsic meaning, see <a href="density_on_a_manifold" title="wikilink">density on a manifold</a>.)</p>
<h3 id="spinors">Spinors</h3>

<p>Starting with an <a href="Orthonormality" title="wikilink">orthonormal</a> coordinate system, a tensor transforms in a certain way when a rotation is applied. However, there is additional structure to the group of rotations that is not exhibited by the transformation law for tensors: see <a href="orientation_entanglement" title="wikilink">orientation entanglement</a> and <a href="plate_trick" title="wikilink">plate trick</a>. Mathematically, the <a href="rotation_group" title="wikilink">rotation group</a> is not <a href="simply_connected" title="wikilink">simply connected</a>. <a href="Spinor" title="wikilink">Spinors</a> are mathematical objects that generalize the transformation law for tensors in a way that is sensitive to this fact.</p>
<h2 id="see-also">See also</h2>
<ul>
<li><a href="Glossary_of_tensor_theory" title="wikilink">Glossary of tensor theory</a></li>
</ul>
<h3 id="notation-1">Notation</h3>
<ul>
<li><a href="Abstract_index_notation" title="wikilink">Abstract index notation</a></li>
<li><a href="Einstein_notation" title="wikilink">Einstein notation</a></li>
<li><a href="Voigt_notation" title="wikilink">Voigt notation</a></li>
<li><a href="Mandel_notation" title="wikilink">Mandel notation</a></li>
<li><a href="Penrose_graphical_notation" title="wikilink">Penrose graphical notation</a></li>
<li><a href="Raising_and_lowering_indices" title="wikilink">Raising and lowering indices</a></li>
</ul>
<h3 id="foundational">Foundational</h3>
<ul>
<li><a href="Covariance_and_contravariance_of_vectors" title="wikilink">Covariance and contravariance of vectors</a></li>
<li><a href="Fibre_bundle" title="wikilink">Fibre bundle</a></li>
<li><a href="One-form" class="uri" title="wikilink">One-form</a></li>
<li><a href="Tensor_field" title="wikilink">Tensor field</a></li>
<li><a href="Tensor_product" title="wikilink">Tensor product</a></li>
<li><a href="Tensor_product_of_modules" title="wikilink">Tensor product of modules</a></li>
</ul>
<h3 id="applications-1">Applications</h3>
<ul>
<li><a href="Covariant_derivative" title="wikilink">Covariant derivative</a></li>
<li><a href="Application_of_tensor_theory_in_engineering" title="wikilink">Application of tensor theory in engineering</a></li>
<li><a href="Curvature" class="uri" title="wikilink">Curvature</a></li>
<li><a href="Diffusion_MRI#Mathematical_foundation&lt;U+2014&gt;tensors" title="wikilink">Diffusion tensor MRI</a></li>
<li><a href="Einstein_field_equations" title="wikilink">Einstein field equations</a></li>
<li><a href="Fluid_mechanics" title="wikilink">Fluid mechanics</a></li>
<li><a href="Riemannian_geometry" title="wikilink">Riemannian geometry</a></li>
<li><a href="Tensor_derivative" title="wikilink">Tensor derivative</a></li>
<li><a href="Tensor_decomposition" title="wikilink">Tensor decomposition</a></li>
<li><a href="Structure_Tensor" title="wikilink">Structure Tensor</a></li>
<li><a href="Tensor_software" title="wikilink">Tensor software</a></li>
</ul>
<h2 id="notes">Notes</h2>

<h2 id="references">References</h2>
<dl>
<dt>General</dt>

</dl>

<ul>
<li></li>
<li></li>
<li></li>
<li></li>
<li></li>
<li>Munkres, James, <em>Analysis on Manifolds,</em> Westview Press, 1991. Chapter six gives a &quot;from scratch&quot; introduction to covariant tensors.</li>
<li></li>
<li></li>
<li>Schutz, Bernard, <em>Geometrical methods of mathematical physics</em>, Cambridge University Press, 1980.</li>
<li></li>
</ul>

<dl>
<dt>Specific</dt>

</dl>


<h2 id="external-links">External links</h2>
<ul>
<li></li>
<li><a href="http://repository.tamu.edu/handle/1969.1/2502">Introduction to Vectors and Tensors, Vol 1: Linear and Multilinear Algebra</a> by Ray M. Bowen and C. C. Wang.</li>
<li><a href="http://repository.tamu.edu/handle/1969.1/3609">Introduction to Vectors and Tensors, Vol 2: Vector and Tensor Analysis</a> by Ray M. Bowen and C. C. Wang.</li>
<li><a href="http://www.grc.nasa.gov/WWW/K-12/Numbers/Math/documents/Tensors_TM2002211716.pdf">An Introduction to Tensors for Students of Physics and Engineering</a> by Joseph C. Kolecki, released by <a href="NASA" class="uri" title="wikilink">NASA</a></li>
<li><a href="http://nrich.maths.org/askedNRICH/edited/2604.html">A discussion of the various approaches to teaching tensors, and recommendations of textbooks</a></li>
<li><a href="http://arxiv.org/abs/math.HO/0403252">A Quick Introduction to Tensor Analysis</a> by R. A. Sharipov.</li>
<li><a href="http://www.e.kth.se/~joakimds">Introduction to Tensors</a> by Joakim Strandberg.</li>
<li><a href="http://www.ece.neu.edu/~kyrgyzov/KyrgyzovO_Dissertation_2010.pdf">Non-Redundant Tensor Decomposition (PhD Dissertation)</a> by Olexiy Kyrgyzov.</li>
</ul>
<p><a href="ar:&lt;U+0645&gt;&lt;U+0648&gt;&lt;U+062A&gt;&lt;U+0631&gt;" class="uri" title="wikilink">ar:&lt;U+0645&gt;&lt;U+0648&gt;&lt;U+062A&gt;&lt;U+0631&gt;</a> <a href="bg:&lt;U+0422&gt;&lt;U+0435&gt;&lt;U+043D&gt;&lt;U+0437&gt;&lt;U+043E&gt;&lt;U+0440&gt;" class="uri" title="wikilink">bg:&lt;U+0422&gt;&lt;U+0435&gt;&lt;U+043D&gt;&lt;U+0437&gt;&lt;U+043E&gt;&lt;U+0440&gt;</a> <a href="ca:Tensor" class="uri" title="wikilink">ca:Tensor</a> <a href="cs:Tenzor" class="uri" title="wikilink">cs:Tenzor</a> <a href="de:Tensor" class="uri" title="wikilink">de:Tensor</a> <a href="et:Tensor" class="uri" title="wikilink">et:Tensor</a> <a href="eo:Tensoro" class="uri" title="wikilink">eo:Tensoro</a> <a href="es:C&lt;U+00E1&gt;lculo_tensorial" title="wikilink">es:C&lt;U+00E1&gt;lculo tensorial</a> <a href="fa:&lt;U+062A&gt;&lt;U+0627&gt;&lt;U+0646&gt;&lt;U+0633&gt;&lt;U+0648&gt;&lt;U+0631&gt;" class="uri" title="wikilink">fa:&lt;U+062A&gt;&lt;U+0627&gt;&lt;U+0646&gt;&lt;U+0633&gt;&lt;U+0648&gt;&lt;U+0631&gt;</a> <a href="fr:Tenseur" class="uri" title="wikilink">fr:Tenseur</a> <a href="gl:Tensor" class="uri" title="wikilink">gl:Tensor</a> <a href="ko:&lt;U+D150&gt;&lt;U+C11C&gt;" class="uri" title="wikilink">ko:&lt;U+D150&gt;&lt;U+C11C&gt;</a> <a href="hi:&lt;U+0906&gt;&lt;U+0924&gt;&lt;U+093E&gt;&lt;U+0928&gt;&lt;U+0915&gt;_&lt;U+0935&gt;&lt;U+093F&gt;&lt;U+0936&gt;&lt;U+094D&gt;&lt;U+0932&gt;&lt;U+0947&gt;&lt;U+0937&gt;&lt;U+0923&gt;" title="wikilink">hi:&lt;U+0906&gt;&lt;U+0924&gt;&lt;U+093E&gt;&lt;U+0928&gt;&lt;U+0915&gt; &lt;U+0935&gt;&lt;U+093F&gt;&lt;U+0936&gt;&lt;U+094D&gt;&lt;U+0932&gt;&lt;U+0947&gt;&lt;U+0937&gt;&lt;U+0923&gt;</a> <a href="hr:Tenzor" class="uri" title="wikilink">hr:Tenzor</a> <a href="it:Tensore" class="uri" title="wikilink">it:Tensore</a> <a href="he:&lt;U+05D8&gt;&lt;U+05E0&gt;&lt;U+05D6&gt;&lt;U+05D5&gt;&lt;U+05E8&gt;" class="uri" title="wikilink">he:&lt;U+05D8&gt;&lt;U+05E0&gt;&lt;U+05D6&gt;&lt;U+05D5&gt;&lt;U+05E8&gt;</a> <a href="hu:Tenzor" class="uri" title="wikilink">hu:Tenzor</a> <a href="nl:Tensor" class="uri" title="wikilink">nl:Tensor</a> <a href="ja:&lt;U+30C6&gt;&lt;U+30F3&gt;&lt;U+30BD&gt;&lt;U+30EB&gt;" class="uri" title="wikilink">ja:&lt;U+30C6&gt;&lt;U+30F3&gt;&lt;U+30BD&gt;&lt;U+30EB&gt;</a> <a href="pl:Tensor" class="uri" title="wikilink">pl:Tensor</a> <a href="pt:Tensor" class="uri" title="wikilink">pt:Tensor</a> <a href="ru:&lt;U+0422&gt;&lt;U+0435&gt;&lt;U+043D&gt;&lt;U+0437&gt;&lt;U+043E&gt;&lt;U+0440&gt;" class="uri" title="wikilink">ru:&lt;U+0422&gt;&lt;U+0435&gt;&lt;U+043D&gt;&lt;U+0437&gt;&lt;U+043E&gt;&lt;U+0440&gt;</a> <a href="sq:Trajtimi_klasik_i_tensor&lt;U+00EB&gt;ve" title="wikilink">sq:Trajtimi klasik i tensor&lt;U+00EB&gt;ve</a> <a href="sk:Tenzor" class="uri" title="wikilink">sk:Tenzor</a> <a href="sl:Tenzor" class="uri" title="wikilink">sl:Tenzor</a> <a href="sr:&lt;U+0422&gt;&lt;U+0435&gt;&lt;U+043D&gt;&lt;U+0437&gt;&lt;U+043E&gt;&lt;U+0440&gt;" class="uri" title="wikilink">sr:&lt;U+0422&gt;&lt;U+0435&gt;&lt;U+043D&gt;&lt;U+0437&gt;&lt;U+043E&gt;&lt;U+0440&gt;</a> <a href="fi:Tensori" class="uri" title="wikilink">fi:Tensori</a> <a href="sv:Tensor" class="uri" title="wikilink">sv:Tensor</a> <a href="uk:&lt;U+0422&gt;&lt;U+0435&gt;&lt;U+043D&gt;&lt;U+0437&gt;&lt;U+043E&gt;&lt;U+0440&gt;" class="uri" title="wikilink">uk:&lt;U+0422&gt;&lt;U+0435&gt;&lt;U+043D&gt;&lt;U+0437&gt;&lt;U+043E&gt;&lt;U+0440&gt;</a> <a href="zh:&lt;U+5F35&gt;&lt;U+91CF&gt;" class="uri" title="wikilink">zh:&lt;U+5F35&gt;&lt;U+91CF&gt;</a></p>
<p><a href="Category:Fundamental_physics_concepts" title="wikilink">Category:Fundamental physics concepts</a> <a href="Category:Introductory_physics" title="wikilink">Category:Introductory physics</a> <a href="Category:Tensors" title="wikilink"> </a></p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1"><a href="#fnref1" class="footnote-back">↩</a></li>
<li id="fn2">Karin Reich, <em>Die Entwicklung des Tensorkalk&lt;U+00FC&gt;ls</em> (1994).<a href="#fnref2" class="footnote-back">↩</a></li>
<li id="fn3"><a href="William_Rowan_Hamilton" title="wikilink">William Rowan Hamilton</a>, <em><a href="http://www.emis.de/classics/Hamilton/ExtQuat.pdf">On some Extensions of Quaternions</a></em><a href="#fnref3" class="footnote-back">↩</a></li>
<li id="fn4">Namely, the <a href="norm_(mathematics)" title="wikilink">norm operation</a> in a certain type of algebraic system (now known as a <a href="Clifford_algebra" title="wikilink">Clifford algebra</a>).<a href="#fnref4" class="footnote-back">↩</a></li>
<li id="fn5">Woldemar Voigt, <a href="http://books.google.com/books?hl=en&amp;id=QhBDAAAAIAAJ&amp;printsec=frontcover&amp;source=web&amp;ots=otxYNFS5zh&amp;sig=HE9YETA1wILEFkD7BVAiKBGrnTU&amp;sa=X&amp;oi=book_result&amp;resnum=4&amp;ct=result"><em>Die fundamentalen physikalischen Eigenschaften der Krystalle in elementarer Darstellung</em></a> (Leipzig, 1898)<a href="#fnref5" class="footnote-back">↩</a></li>
<li id="fn6">In volume XVI of the <em>Bulletin des Sciences Math&lt;U+00E9&gt;matiques</em>.<a href="#fnref6" class="footnote-back">↩</a></li>
<li id="fn7"><a href="Abraham_Pais" title="wikilink">Abraham Pais</a>, <em>Subtle is the Lord: The Science and the Life of Albert Einstein</em><a href="#fnref7" class="footnote-back">↩</a></li>
<li id="fn8">Judtih R. Goodstein, <em><a href="http://www3.interscience.wiley.com/journal/120043907/abstract">The Italian Mathematicians of Relativity</a></em> (2007)<a href="#fnref8" class="footnote-back">↩</a></li>
<li id="fn9">This article will be using the term <em>order</em>, since the term <em>rank</em> has a different meaning in the related context of matrices.<a href="#fnref9" class="footnote-back">↩</a></li>
<li id="fn10">There is a plethora of different terminology for this around. The terms order, type, rank, valence, and degree are in use for the same concept. This article uses the term &quot;order&quot; or &quot;total order&quot; for the total dimension of the array (or its generalisation in other definitions) <em>m</em> in the preceding example, and the term type for the pair giving the number contravariant and covariant indices. A tensor of type  will also be referred to as a &quot;&quot; tensor for short.<a href="#fnref10" class="footnote-back">↩</a></li>
<li id="fn11"></li>
<li id="fn12"><a href="#fnref12" class="footnote-back">↩</a></li>
<li id="fn13"><a href="#fnref13" class="footnote-back">↩</a></li>
<li id="fn14"><a href="#fnref14" class="footnote-back">↩</a></li>
<li id="fn15"><a href="#fnref15" class="footnote-back">↩</a></li>
<li id="fn16"><a href="#fnref16" class="footnote-back">↩</a></li>
<li id="fn17"><a href="#fnref17" class="footnote-back">↩</a></li>
</ol>
</section>
